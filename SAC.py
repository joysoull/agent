"""
åŒå±‚æ·±åº¦å¼ºåŒ–å­¦ä¹ ç³»ç»Ÿ
==============================
ä¸Šå±‚ (Level-1): ä»»åŠ¡å›¾åˆ’åˆ† - ä½¿ç”¨GNN+PPO
ä¸‹å±‚ (Level-2): æ™ºèƒ½ä½“é€‰æ‹©å’Œè®¾å¤‡éƒ¨ç½² - ä½¿ç”¨Attention+SAC

"""
import json
import os
import random
from collections import defaultdict, deque
import time
from typing import Dict, List, Tuple, Any, Optional, cast
import hashlib
import gymnasium as gym
import networkx as nx
import numpy as np
import pandas as pd
import torch

from gymnasium import spaces
from gymnasium.utils import seeding

from stable_baselines3.common.callbacks import BaseCallback

from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.monitor import Monitor  # åœ¨æ–‡ä»¶é¡¶éƒ¨æ·»åŠ å¯¼å…¥

from cSAC import CSACConfig, ConstrainedDiscreteSAC, _to_torch_obs
from simulation import Device, device_number, Resource
from sub_partiation import AgentTemplate, parse_capability_field

WHITE_NOISE = 1e-9  # W

# ---------- å¸¸é‡ ----------
P_TX_IOT = 0.10  # W   100â€¯mW
P_RX_IOT = 0.10
P_TX_AP = 0.025  # W    25â€¯mW
P_RX_AP = 0.025

h_e, h_c = 3, 5
E_edge, E_core = 37e-9, 12.6e-9  # J/bit
E_cent = 20e-9  # J/bit
E_per_bit_wired = h_e * E_edge + h_c * E_core + E_cent  # â‰ˆ2.075eâ€‘5â€¯J/bit


def load_infrastructure(config_path="infrastructure_config.json", gw_path="gw_matrix.npy"):
    # è¯»å– JSON æ–‡ä»¶
    with open(config_path, "r") as f:
        data = json.load(f)

    # è§£æäº‘æœåŠ¡å™¨
    cloud_data = data["cloud_server"]
    cloud = Device(
        type=cloud_data["type"],
        id=cloud_data["id"],
        resource=Resource(**cloud_data["resource"]),
        act_cap=set(cloud_data["act_cap"]),
        sense_cap=set(cloud_data["sense_cap"]),
        soft_cap=set(cloud_data["soft_cap"]),
        bandwidth=cloud_data["bandwidth"],
        delay=cloud_data["delay"],
    )

    # è§£æ IoT è®¾å¤‡åˆ—è¡¨
    device_list = []
    for dev in data["device_list"]:
        device_list.append(Device(
            type=dev["type"],
            id=dev["id"],
            resource=Resource(**dev["resource"]),
            act_cap=set(dev["act_cap"]),
            sense_cap=set(dev["sense_cap"]),
            soft_cap=set(dev["soft_cap"]),
            bandwidth=dev["bandwidth"],
            delay=dev["delay"],
        ))

    # è§£æè¾¹ç¼˜æœåŠ¡å™¨åˆ—è¡¨
    edge_list = []
    for edge in data["edge_server_list"]:
        edge_list.append(Device(
            type=edge["type"],
            id=edge["id"],
            resource=Resource(**edge["resource"]),
            act_cap=set(edge["act_cap"]),
            sense_cap=set(edge["sense_cap"]),
            soft_cap=set(edge["soft_cap"]),
            bandwidth=edge["bandwidth"],
            delay=edge["delay"],
        ))

    # è¯»å–ç½‘å…³çŸ©é˜µ
    gw_matrix = np.load(gw_path)

    return cloud, device_list, edge_list, gw_matrix


def build_agent_lookup(df) -> Dict[int, AgentTemplate]:
    lookup = {}
    for _, row in df.iterrows():
        agent_id = row["Agent ID"]
        C_sense = parse_capability_field(row["Sense Capabilities"])
        C_act = parse_capability_field(row["Act Capabilities"])
        C_soft = parse_capability_field(row["Soft Capabilities"])
        r = (
            row["CPU (FLOPs)"] * 1e9,
            row["CPU Count"],
            row["GPU (FLOPs)"] * 1e12,
            row["GPU Memory (GB)"],
            row["RAM (GB)"],
            row["Disk (GB)"]
        )
        lookup[agent_id] = AgentTemplate(agent_id, C_sense, C_act, C_soft, r)
    return lookup


def _get_transmission_time_s(data_size_mb, rate_mbps):
    if rate_mbps <= 0:
        return float("inf")
    return (8.0 * data_size_mb) / rate_mbps


def compute_transmission_delay(src, dst,
                               data_size_mb,
                               bw_req,  # ä¸šåŠ¡æœ€å°å¸¦å®½éœ€æ±‚ï¼Œå¯ç”¨äºé€Ÿç‡ä¸‹é™
                               gw_matrix,
                               edge_inter_delay=1, cloud_edge_delay=20,
                               ):
    """
    è¿”å›:
    1. æ€»é“¾è·¯å»¶è¿Ÿ (ms)
    2. å®é™…å¯ç”¨å¸¦å®½ (Mbps), ç”¨äºè¿è§„æ£€æŸ¥
    3. æ€»é€šä¿¡èƒ½è€— (J)
    """
    # ---------------- 0. åŒè®¾å¤‡ ----------------
    if src.id == dst.id:
        return 0.0, True, 0.0

    # ---------- ç±»å‹å¸ƒå°” ----------
    src_iot = src.type == "Device"
    dst_iot = dst.type == "Device"
    src_edge = src.type == "Edge"
    dst_edge = dst.type == "Edge"
    src_cloud = src.type == "Cloud"
    dst_cloud = dst.type == "Cloud"

    bits = data_size_mb * 8 * 1e6  # è½¬ bit

    # ---------- è¾…åŠ©: è®¡ç®— UL / DL delay ----------
    # ------- å­å‡½æ•°ï¼šUL / DL -------
    # ------ UL / DL helper ------
    # ------ UL / DL helper (å·²ä¿®æ­£) ------

    def ul_delay_energy(dev_iot):
        # <<< FIX: ä½¿ç”¨ dev_iot çš„å±æ€§ï¼Œè€Œä¸æ˜¯å…¨å±€çš„ src >>>
        rate = dev_iot.bandwidth  # Mbps
        prop_delay = dev_iot.delay  # ms
        gw_row = gw_matrix[dev_iot.id - 1]
        gw_idx = int(np.where(gw_row > 0)[0][0]) if np.any(gw_row > 0) else -1

        # <<< FIX: æ­£ç¡®è®¡ç®—ä¼ è¾“æ—¶é—´ã€æ€»å»¶è¿Ÿå’Œèƒ½è€— >>>
        transmission_time_s = _get_transmission_time_s(data_size_mb, rate)
        total_delay_ms = transmission_time_s * 1000 + prop_delay
        energy_j = (P_TX_IOT + P_RX_AP) * transmission_time_s

        # <<< FIX: è¿”å›å®é™…é€Ÿç‡å’Œä»¥ç„¦è€³ä¸ºå•ä½çš„èƒ½è€— >>>
        return total_delay_ms, rate, energy_j, gw_idx

    def dl_delay_energy(dev_iot, gw_idx):
        # <<< FIX: ä½¿ç”¨ dev_iot çš„å±æ€§ >>>
        # æ³¨æ„ï¼šä¸‹è¡Œé€Ÿç‡å¯èƒ½ä¸ä¸Šè¡Œä¸åŒï¼Œè¿™é‡Œä¸ºç®€åŒ–å‡è®¾ç›¸åŒï¼Œå®é™…å¯ä»dev_iotæˆ–gwè·å–
        rate = dev_iot.bandwidth
        prop_delay = dev_iot.delay

        # <<< FIX: æ­£ç¡®è®¡ç®— >>>
        transmission_time_s = _get_transmission_time_s(data_size_mb, rate)
        total_delay_ms = transmission_time_s * 1000 + prop_delay
        energy_j = (P_TX_AP + P_RX_IOT) * transmission_time_s

        # <<< FIX: è¿”å›å®é™…é€Ÿç‡å’Œä»¥ç„¦è€³ä¸ºå•ä½çš„èƒ½è€— >>>
        return total_delay_ms, rate, energy_j

    # ------ åœºæ™¯ 1: IoT â†’ IoT ------
    if src_iot and dst_iot:
        T_ul, rate_ul, E_ul, gw_u = ul_delay_energy(src)
        T_dl, rate_dl, E_dl, = dl_delay_energy(dst, gw_u)
        same_gw = gw_u == np.where(gw_matrix[dst.id - 1] > 0)[0][0]

        total_delay = T_ul + T_dl + (0 if same_gw else edge_inter_delay)
        total_energy = E_ul + E_dl
        # <<< FIX: è¿”å›ç“¶é¢ˆå¸¦å®½ >>>
        bottleneck_rate = min(rate_ul, rate_dl)
        return total_delay, bottleneck_rate, total_energy

    # ------ IoT â†’ Edge ------
    if src_iot and dst_edge:
        T_ul, rate_ul, E_ul, _ = ul_delay_energy(src)
        E_wired = E_per_bit_wired * bits
        # <<< FIX: è¿”å›æ­£ç¡®çš„æ€»å»¶è¿Ÿã€å®é™…å¸¦å®½å’Œæ€»èƒ½è€— >>>
        return T_ul + edge_inter_delay, rate_ul, E_ul + E_wired
    # ------ IoT â†’ Cloud ------
    if src_iot and dst_cloud:
        T_ul, rate_ul, E_ul, _ = ul_delay_energy(src)
        E_wired = E_per_bit_wired * bits
        return T_ul + cloud_edge_delay, rate_ul, E_ul + E_wired
    # ------ Edge â†’ IoT ------
    if src_edge and dst_iot:
        gw_idx = np.where(gw_matrix[dst.id - 1] > 0)[0][0]
        T_dl, rate_dl, E_dl = dl_delay_energy(dst, gw_idx)
        E_wired = E_per_bit_wired * bits
        return T_dl + edge_inter_delay, rate_dl, E_dl + E_wired
    # ------ Cloud â†’ IoT ------
    if src_cloud and dst_iot:
        gw_idx = np.where(gw_matrix[dst.id - 1] > 0)[0][0]
        T_dl, rate_dl, E_dl = dl_delay_energy(dst, gw_idx)
        E_wired = E_per_bit_wired * bits
        return T_dl + cloud_edge_delay, rate_dl, E_dl + E_wired
    # --- æœ‰çº¿è¿æ¥åœºæ™¯ ---
    # å‡è®¾æœ‰çº¿å¸¦å®½è¿œå¤§äºæ— çº¿ï¼Œä¸ä¼šæˆä¸ºç“¶é¢ˆ
    WIRED_BANDWIDTH = 1000.0  # å‡è®¾ 1 Gbps

    # ------ Edge â†” Edge ------
    if src_edge and dst_edge:
        E_wired = E_per_bit_wired * bits
        # <<< FIX: è¿”å›ç»Ÿä¸€æ ¼å¼ (delay, bw, energy) >>>
        return edge_inter_delay, WIRED_BANDWIDTH, E_wired

    # ------ Cloud â†” Edge ------
    if (src_cloud and dst_edge) or (src_edge and dst_cloud):
        E_wired = E_per_bit_wired * bits
        # <<< FIX: è¿”å›ç»Ÿä¸€æ ¼å¼ >>>
        return cloud_edge_delay, WIRED_BANDWIDTH, E_wired

    # é»˜è®¤æƒ…å†µï¼Œä¸åº”è¯¥å‘ç”Ÿ
    return float('inf'), 0.0, float('inf')


class TaskGraph:
    def __init__(self):
        self.G = nx.DiGraph()
        self.id = 0

    def load_from_json(self, json_data, task_id):
        self.id = task_id
        # åŠ è½½èŠ‚ç‚¹
        for node in json_data["nodes"]:
            node_id = node["id"]
            node_type = node.get("type", "proc")
            idx = node.get("idx", -1)

            self.G.add_node(node_id, type=node_type, idx=idx)

        # åŠ è½½è¾¹
        for link in json_data["links"]:
            source = link["source"]
            target = link["target"]

            self.G.add_edge(
                source, target,
                data_size=link["data_size"],  # MB
                bandwidth_req=link["bandwidth_req"],  # Mbps
                latency_req=link["latency_req"]  # ms
            )

    def get_proc_nodes(self):
        return [n for n, attr in self.G.nodes(data=True) if attr['type'] == 'proc']

    def get_sense_nodes(self):
        return [n for n, attr in self.G.nodes(data=True) if attr['type'] == 'sense']

    def get_act_nodes(self):
        return [n for n, attr in self.G.nodes(data=True) if attr['type'] == 'act']

    def get_all_capability_nodes(self):
        return list(self.G.nodes)

    def get_dependencies(self):
        return list(self.G.edges(data=True))


def norm_latency(actual_ms, req_ms):
    if req_ms is None or req_ms <= 0:  # æ— çº¦æŸ
        return 0.0
    return max((actual_ms - req_ms) / max(req_ms, 1e-6), 0.0)


def norm_bandwidth(actual_mbps, req_mbps):
    if req_mbps is None or req_mbps <= 0:  # æ— çº¦æŸ
        return 0.0
    # éœ€è¦å¸¦å®½ï¼Œå®é™…ä¸è¶³æ‰è¿å
    return max((req_mbps - actual_mbps) / max(req_mbps, 1e-6), 0.0)


# <<< NEW: ä¼ æ„Ÿå™¨åä½œæƒ©ç½š >>>
# å½“ä¸€ä¸ªæ¨¡å—ç¼ºå¤±çš„ä¼ æ„Ÿå™¨èƒ½åŠ›éœ€è¦ç”±å¦ä¸€ä¸ªæ¨¡å—æä¾›æ—¶ï¼Œæ–½åŠ çš„æƒ©ç½šå€¼
COLLABORATION_PENALTY_PER_CAP = 1.0
# ä¸ºäº†åŒºåˆ†ï¼Œæˆ‘ä»¬ç»™æ— æ³•åä½œçš„èƒ½åŠ›ä¸€ä¸ªæ›´é«˜çš„åŸºç¡€æƒ©ç½š
UNSOLVABLE_MISMATCH_PENALTY = 10.0
# <<< NEW: å°†å¥–åŠ±æƒé‡å®šä¹‰ä¸ºç±»å¸¸é‡ï¼Œæ–¹ä¾¿è°ƒä¼˜ >>>
# æƒ©ç½šé¡¹æƒé‡ (æ•°å€¼è¶Šå¤§ï¼Œä»£è¡¨è¶Šä¸å¸Œæœ›å‘ç”Ÿ)
W_CAP_VIOLATION = 2.0  # èƒ½åŠ›è¿å
W_RES_VIOLATION = 2.0  # èµ„æºè¿å
W_LAT_VIOLATION = 2.5  # å»¶è¿Ÿè¿å (ç»™äºˆæ›´é«˜æƒé‡ï¼Œå› ä¸ºå®ƒå½±å“makespan)
W_BW_VIOLATION = 1.5  # å¸¦å®½è¿å
W_LAT_SHAPING = 0.15  # å»ºè®® 0.1 ~ 0.2
W_BW_SHAPING = 0.10  # å»ºè®® 0.05 ~ 0.15
# æˆæœ¬é¡¹æƒé‡ (ä½œä¸ºè´Ÿå¥–åŠ±)
W_COMM_ENERGY = 0.5  # é€šä¿¡èƒ½è€—
W_EXEC_ENERGY = 0.3  # è®¡ç®—èƒ½è€—
# â€”â€” ç»ˆå±€å¥–åŠ±å»ºè®®ï¼šä¿æŒä¸æ¯ä¸ª episode çš„ step ç´¯ç§¯åŒé‡çº§ï¼ˆ~1-3ï¼‰â€”â€”
FINISH_BONUS = 40  # æˆåŠŸå°å¹…æ­£å¥–åŠ±
FAIL_PENALTY = 40  # å¤±è´¥å°å¹…è´Ÿå¥–åŠ±
K_LEFTOVER = 20  # æœªå®Œæˆæ¯”ä¾‹çš„æ‰£åˆ†æƒé‡
K_SOFT_OVER = 50  # è½¯çº¦æŸï¼ˆlat/bwï¼‰è¶…é™çš„æ‰£åˆ†æƒé‡
K_HARD_VIOL = 0.2  # ç¡¬è¿è§„è®¡æ•°çš„æ‰£åˆ†æƒé‡
# è¿›åº¦å¥–åŠ±
R_PROGRESS = 1  # æˆåŠŸéƒ¨ç½²ä¸€ä¸ªæ¨¡å—çš„å¥–åŠ±
# ç¡¬è¿è§„çš„ step è´Ÿå¥–åŠ±ç³»æ•°ï¼ˆPPO éœ€è¦è¿™ä¸ªï¼‰
P_ILLEGAL = 0.25  # æ¯ä¸ªéæ³•å­ä½ï¼ˆcompute/sense/actï¼‰æƒ©ç½š
P_CAP = 0.50  # èƒ½åŠ›ä¸åŒ¹é…ï¼ˆæŒ‰ç¼ºå¤±æ•°è®¡ï¼‰
P_RESOURCE = 0.75  # èµ„æºè¶Šç•Œï¼ˆä¸€æ¬¡å°±ç»™è¿™æ¡£ï¼‰
# æˆªæ–­æƒ©ç½š
TRUNC_PENALTY = 10.0

# Level-1 ç¯å¢ƒæ˜¯å¦å¸æ”¶ Level-2 çš„å¥–åŠ±
L1_TAKES_L2_REWARD_COEF = 0.0  # å»ºè®®è®¾ä¸º0ï¼Œæˆ–å¾ˆå°çš„å€¼å¦‚0.1

# é€šä¿¡èƒ½è€—ä¼°è®¡ç”¨çš„æœ‰çº¿èƒ½è€—å¸¸æ•°ï¼ˆJ/bitï¼‰ï¼Œç”¨äºå½’ä¸€åŒ–åˆ†æ¯ä¼°è®¡
COMM_ENERGY_PER_BIT_WIRED = 2.075e-5

W_FINAL_MAKESPAN = 12
W_FINAL_ENERGY = 2.5
W_FINAL_PENALTY = 1.0

# <<< NEW: å®šä¹‰å…¨å±€è·¯å¾„å˜é‡ >>>
LOG_DIR = "logs"
PLOT_DIR = "plots"
MODEL_DIR = "models"

# --- GRASP + LNS (joint partition & match) ---
from grasp_lns import (
    solve_stage1_partition_and_match,
    GRASP_DEFAULT_WEIGHTS, Weights, GRASPParams,
)


def _dag_fingerprint(G: nx.DiGraph) -> str:
    """
    ä¸º DAG ç”Ÿæˆä¸€ä¸ªç¨³å®šçš„æŒ‡çº¹ï¼Œç”¨äºæ ¸å¯¹è®¡åˆ’æ˜¯å¦ä¸å½“å‰ä»»åŠ¡å›¾ä¸€è‡´ã€‚
    åŒ…å«ï¼šèŠ‚ç‚¹(å«type/idx) + æœ‰å‘è¾¹é›†åˆã€‚
    """
    nodes_sig = []
    for n, d in G.nodes(data=True):
        nodes_sig.append((str(n), d.get("type", ""), int(d.get("idx", -1))))
    nodes_sig.sort()

    edges_sig = []
    for u, v, a in G.edges(data=True):
        # åªè¦ç»“æ„ï¼Œä¸å¸¦æƒï¼ˆå¦‚éœ€å¸¦ä¸Šå¸¦å®½/æ•°æ®é‡ï¼Œå¯æ‹¼è¿›æ¥ï¼‰
        edges_sig.append((str(u), str(v)))
    edges_sig.sort()

    m = hashlib.sha256()
    m.update(json.dumps(nodes_sig).encode("utf-8"))
    m.update(json.dumps(edges_sig).encode("utf-8"))
    return m.hexdigest()


def serialize_partition_plan(G: nx.DiGraph, plan: Dict[str, Any]) -> Dict[str, Any]:
    """
    æ–°å¼ç‰ˆæœ¬ï¼šserialize_partition_plan(G, plan)

    plan éœ€è¦åŒ…å«:
      - "task_id": int
      - "objective": float (å¯é€‰)
      - "modules": [
            {
              "module_id": int,
              "agent_id": int,
              "nodes": Iterable[str or int]
            }, ...
        ]

    è¿”å›ç»Ÿä¸€ JSON friendly ç»“æ„:
    {
      "fingerprint": <str>,
      "task_id": <int>,
      "objective": <float or None>,
      "modules": [
        {"module_id": int, "agent_id": int, "nodes": [str, ...]}, ...
      ]
    }
    """

    def _norm_nodes(seq) -> List[str]:
        # èŠ‚ç‚¹IDç»Ÿä¸€è½¬å­—ç¬¦ä¸² & æ’åº
        return sorted([str(x) for x in seq])

    out_modules: List[Dict[str, Any]] = []
    for m in plan.get("modules", []):
        out_modules.append({
            "module_id": int(m["module_id"]),
            "agent_id": int(m.get("agent_id", -1)),
            "nodes": _norm_nodes(m["nodes"]),
        })
    out_modules.sort(key=lambda x: x["module_id"])

    return {
        "fingerprint": _dag_fingerprint(G),
        "task_id": int(plan.get("task_id", -1)),
        "objective": (
            None if plan.get("objective") is None
            else float(plan["objective"])
        ),
        "modules": out_modules,
    }


def save_partition_plans(plans_by_task: Dict[int, Dict[str, Any]], path: str):
    """
    plans_by_task: { task_id -> serialized_plan_dict }
    """
    with open(path, "w", encoding="utf-8") as f:
        json.dump(plans_by_task, f, ensure_ascii=False, indent=2)


def load_partition_plans(path: str) -> Dict[int, Dict[str, Any]]:
    with open(path, "r", encoding="utf-8") as f:
        raw = json.load(f)
    # å…¼å®¹ä¸¤ç§æ ¼å¼ï¼šå­—å…¸æˆ–åˆ—è¡¨
    if isinstance(raw, list):
        return {int(p["task_id"]): p for p in raw}
    elif isinstance(raw, dict):
        # å¯èƒ½æ˜¯ {task_id: plan} æˆ– {"plans":[...]}
        if "plans" in raw and isinstance(raw["plans"], list):
            return {int(p["task_id"]): p for p in raw["plans"]}
        return {int(k): v for k, v in raw.items()}
    else:
        raise ValueError("Unknown JSON format for precomputed plans")


def realize_plan_to_modules_queue(plan: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    å°†åºåˆ—åŒ–çš„ plan è½¬å› env çš„ modules_queue ç»“æ„ã€‚
    """
    out = []
    for m in sorted(plan["modules"], key=lambda x: x["module_id"]):
        out.append({
            "module_id": int(m["module_id"]),
            "agent_id": int(m["agent_id"]),
            "nodes": set(m["nodes"]),  # env å†…éƒ¨ç”¨ set
        })
    return out


# --- å…¨å±€è¾…åŠ©å‡½æ•° ---
def get_module_capabilities(G: nx.DiGraph, nodes: set) -> Tuple[set, set, set]:
    C_sense, C_act, C_soft = set(), set(), set()
    for node in nodes:
        if node not in G.nodes:
            continue
        node_type = G.nodes[node].get("type")
        idx = G.nodes[node].get("idx")
        if node_type == "sense":
            C_sense.add(idx)
        elif node_type == "act":
            C_act.add(idx)
        elif node_type == "proc":
            C_soft.add(idx)
    return C_sense, C_act, C_soft


def get_agent_capabilities(agent: AgentTemplate) -> Tuple[set, set, set]:
    return agent.C_sense, agent.C_act, agent.C_soft


# ä½ æä¾›çš„ç”¨äºè®¡ç®— makespan çš„å‡½æ•°ï¼Œæˆ‘ä»¬æŠŠå®ƒæ”¾åœ¨è¿™é‡Œä»¥ç¡®ä¿ä¾èµ–å®Œæ•´
def compute_task_finish_time(task_id: int,
                             agent_dag_edges: List[Tuple[Any, Any, Dict]],
                             exec_time_map: Dict[Tuple[int, int], float],
                             edge_delay_map: Dict[Tuple[int, int, int], float]) -> float:
    """
    è®¡ç®—å¹¶è¿”å›ä»»åŠ¡çš„ makespan (T_m_total)ã€‚
    """
    succ = defaultdict(list)
    indeg = defaultdict(int)
    modules_in_task = set()

    # 1. æ„å»ºé‚»æ¥è¡¨ & å…¥åº¦
    for u_mod, v_mod, attr in agent_dag_edges:
        succ[u_mod].append(v_mod)
        indeg[v_mod] += 1
        modules_in_task.update([u_mod, v_mod])

    # 2. æ‹“æ‰‘æ’åºè®¡ç®—æœ€æ—©å®Œæˆæ—¶é—´
    q = deque()
    earliest_finish = {}

    # æ‰¾åˆ°æ‰€æœ‰æºèŠ‚ç‚¹
    for mod in modules_in_task:
        if indeg[mod] == 0:
            earliest_finish[mod] = 0.0
            q.append(mod)

    while q:
        u = q.popleft()
        # èŠ‚ç‚¹uçš„å®Œæˆæ—¶é—´ = uçš„å¼€å§‹æ—¶é—´ + uçš„æ‰§è¡Œæ—¶é—´
        base_finish_time = earliest_finish.get(u, 0.0) + exec_time_map.get((task_id, u), 0.0)

        for v in succ[u]:
            # vçš„å¼€å§‹æ—¶é—´æ˜¯æ‰€æœ‰å‰é©±å®Œæˆæ—¶é—´çš„æœ€å¤§å€¼
            edge_delay = edge_delay_map.get((task_id, u, v), 0.0)
            candidate_start_time = base_finish_time + edge_delay
            earliest_finish[v] = max(earliest_finish.get(v, 0.0), candidate_start_time)

            indeg[v] -= 1
            if indeg[v] == 0:
                q.append(v)

    # 3. æ‰¾åˆ°æ‰€æœ‰æ±‡èŠ‚ç‚¹ï¼ˆæ²¡æœ‰åç»§çš„èŠ‚ç‚¹ï¼‰çš„æœ€å¤§å®Œæˆæ—¶é—´
    max_finish = 0.0
    for mod in modules_in_task:
        if not succ[mod]:
            # æ±‡èŠ‚ç‚¹çš„å®Œæˆæ—¶é—´ = å®ƒçš„å¼€å§‹æ—¶é—´ + å®ƒçš„æ‰§è¡Œæ—¶é—´
            finish_time = earliest_finish.get(mod, 0.0) + exec_time_map.get((task_id, mod), 0.0)
            max_finish = max(max_finish, finish_time)

    return max_finish


def evaluation_func_rl(
        placement: Dict[Tuple[int, int], Dict],
        task_graph: 'TaskGraph',  # ä½¿ç”¨å¼•å·é¿å…å¾ªç¯å¯¼å…¥
        agent_lookup: Dict[int, 'AgentTemplate'],
        device_map: Dict[int, 'Device'],
        gw_matrix: np.ndarray
) -> tuple[float, float, float] | tuple[float, float, dict[str, float]]:
    """
    æ–¹æ¡ˆBï¼šæ„é€ "ä¸‰ç›¸ä½"æ¨¡å—å›¾ï¼ˆpre/core/postï¼‰ï¼Œ
    - preâ†’core æ‰¿è½½æ¨¡å—å†… Sâ†’P çš„æœ€å¤§å»¶è¿Ÿ
    - core æ‰¿è½½æ‰§è¡Œæ—¶é—´
    - coreâ†’post æ‰¿è½½æ¨¡å—å†… Pâ†’A çš„æœ€å¤§å»¶è¿Ÿ
    - è·¨æ¨¡å—è¾¹ç»Ÿä¸€ç”¨ U(core)â†’V(core) æ‰¿è½½é€šä¿¡å»¶è¿Ÿ
    ä»…è¿”å› makespanï¼Œèƒ½è€—ä¸æƒ©ç½šç½® 0.0
    """
    # --- åˆå§‹åŒ– ---
    # --- æ˜ å°„ï¼šèŠ‚ç‚¹ -> æ¨¡å— ---
    node_to_module_map: Dict[str, int] = {}
    task_id = -1
    for (tid, mod_id), mod_info in placement.items():
        task_id = tid
        for node in mod_info["nodes"]:
            node_to_module_map[node] = mod_id
    if task_id == -1:
        return -1.0, 0.0, 0.0  # ç©ºæ–¹æ¡ˆ

    # 2) è¾…åŠ©ï¼šæŸ¥èŠ‚ç‚¹è½åœ¨å“ªä¸ªè®¾å¤‡
    def get_device_for_node(node_id: str) -> Optional[int]:
        module_id = node_to_module_map.get(node_id)
        if module_id is None:
            return None
        mod_place = placement.get((task_id, module_id))
        if mod_place is None:
            return None

        ninfo = task_graph.G.nodes[node_id]
        ntype = ninfo.get("type", "proc")
        if ntype == "proc":
            return mod_place["soft_device"]
        idx = ninfo.get("idx")
        if ntype == "sense":
            return mod_place["sense_map"].get(idx)
        if ntype == "act":
            return mod_place["act_map"].get(idx)
        return None

    # --- 1) æ¯ä¸ªæ¨¡å—çš„æ‰§è¡Œæ—¶é—´ï¼ˆcore phaseï¼‰ ---
    exec_time_map: Dict[Tuple[int, Any], float] = {}  # (task_id, phase_node) -> time(s)
    for (tid, module_id), info in placement.items():
        agent = agent_lookup[info["agent_id"]]
        res = device_map[info["soft_device"]].resource
        r_cpu, _, r_gpu, _, _, _ = agent.r
        cpu_cap = float(getattr(res, "cpu", 0.0))
        gpu_cap = float(getattr(res, "gpu", 0.0))
        cpu_time = (r_cpu / cpu_cap) if cpu_cap > 0 else 0.0
        gpu_time = (r_gpu / gpu_cap) if gpu_cap > 0 else 0.0
        core_time = max(cpu_time, gpu_time)

        n_pre, n_core, n_post = (module_id, "pre"), (module_id, "core"), (module_id, "post")
        exec_time_map[(task_id, n_pre)] = 0.0
        exec_time_map[(task_id, n_core)] = float(core_time)
        exec_time_map[(task_id, n_post)] = 0.0
    # --- 2) ç»Ÿè®¡æ¨¡å—å†… Sâ†’P / Pâ†’A çš„æœ€å¤§é“¾è·¯æ—¶å»¶ï¼ˆä»…è·¨è®¾å¤‡æ‰æœ‰æ—¶å»¶ï¼‰ ---
    intra_pre_ms = defaultdict(float)  # æ¨¡å—å†… Sâ†’P
    intra_post_ms = defaultdict(float)  # æ¨¡å—å†… Pâ†’A
    for u, v, attr in task_graph.get_dependencies():
        u_mod, v_mod = node_to_module_map.get(u), node_to_module_map.get(v)
        if u_mod != v_mod or u_mod is None:
            continue
        du, dv = get_device_for_node(u), get_device_for_node(v)
        if du is None or dv is None or du == dv:
            continue
        delay_ms, _, _ = compute_transmission_delay(
            src=device_map[du], dst=device_map[dv],
            data_size_mb=attr.get("data_size", 0.0),
            bw_req=attr.get("bandwidth_req", 0.0),
            gw_matrix=gw_matrix
        )
        u_type, v_type = task_graph.G.nodes[u].get("type"), task_graph.G.nodes[v].get("type")
        if u_type == "sense" and v_type == "proc":
            intra_pre_ms[u_mod] = max(intra_pre_ms[u_mod], delay_ms)
        elif u_type == "proc" and v_type == "act":
            intra_post_ms[u_mod] = max(intra_post_ms[u_mod], delay_ms)

    # --- 3) ç»„è£…ä¸‰ç›¸ä½å›¾çš„è¾¹ä¸å»¶è¿Ÿ ---
    agent_dag_edges: List[Tuple[Any, Any, Dict]] = []  # (phase_u, phase_v, {})
    edge_delay_map: Dict[Tuple[int, Any, Any], float] = {}  # (task_id, phase_u, phase_v) -> delay(s)
    # 3a) æ¨¡å—å†… preâ†’coreã€coreâ†’postï¼ˆms -> sï¼‰
    for (tid, module_id), _ in placement.items():
        n_pre = (module_id, "pre")
        n_core = (module_id, "core")
        n_post = (module_id, "post")

        agent_dag_edges.append((n_pre, n_core, {}))
        edge_delay_map[(task_id, n_pre, n_core)] = intra_pre_ms[module_id] / 1000.0

        agent_dag_edges.append((n_core, n_post, {}))
        edge_delay_map[(task_id, n_core, n_post)] = intra_post_ms[module_id] / 1000.0
    # 3b) è·¨æ¨¡å—è¾¹ï¼šç»Ÿä¸€ç”¨ U(core) â†’ V(core)ï¼Œå»¶è¿Ÿå–è¯¥è¾¹è·¨è®¾å¤‡é€šä¿¡ï¼ˆms -> sï¼‰
    # è‹¥åŒä¸€æ¨¡å—å¯¹ä¹‹é—´å¤šæ¡è¾¹ï¼Œå–æœ€å¤§å»¶è¿Ÿï¼ˆå…³é”®è·¯å¾„ï¼‰
    # --- 3b) è·¨æ¨¡å—è¾¹ï¼ˆå«é˜»å¡å»¶è¿Ÿï¼‰ ---
    inter_core_delay_sec = defaultdict(float)
    incoming_trans_delay = defaultdict(list)
    for u, v, attr in task_graph.get_dependencies():
        u_mod, v_mod = node_to_module_map.get(u), node_to_module_map.get(v)
        if u_mod is None or v_mod is None or u_mod == v_mod:
            continue

        du, dv = get_device_for_node(u), get_device_for_node(v)
        if du is None or dv is None:
            continue

        d_ms, _, _ = compute_transmission_delay(
            src=device_map[du], dst=device_map[dv],
            data_size_mb=attr.get("data_size", 1.0),
            bw_req=attr.get("bandwidth_req", 0.0),
            gw_matrix=gw_matrix
        )
        delay_sec = float(d_ms) / 1000.0

        # âœ… æ¨¡å—é˜»å¡å»¶è¿Ÿ
        src_exec = exec_time_map.get((task_id, (u_mod, "core")), 0.0)
        # è‹¥æ¨¡å—å†…å­˜åœ¨å¤šä¸ªprocèŠ‚ç‚¹ï¼Œåˆ™è®¤ä¸ºé˜»å¡å®Œæ•´æ‰§è¡Œæ—¶é—´
        num_proc = len([n for n in task_graph.G.nodes()
                        if node_to_module_map.get(n) == u_mod and
                        task_graph.G.nodes[n].get("type") == "proc"])
        block_wait = src_exec if num_proc > 1 else 0.0
        total_delay = delay_sec + block_wait

        u_core, v_core = (u_mod, "core"), (v_mod, "core")
        inter_core_delay_sec[(u_core, v_core)] = max(inter_core_delay_sec[(u_core, v_core)], total_delay)
        incoming_trans_delay[v_core].append(total_delay)
    for (u_core, v_core), dsec in inter_core_delay_sec.items():
        agent_dag_edges.append((u_core, v_core, {}))
        edge_delay_map[(task_id, u_core, v_core)] = dsec
    # --- 3c) æ¨¡å—åŒæ­¥å¯åŠ¨ç­‰å¾…ï¼ˆè¾“å…¥æœ€å¤§å»¶è¿Ÿï¼‰ ---
    sync_wait_map = {m: max(v) if v else 0.0 for m, v in incoming_trans_delay.items()}
    for (tid, module_id), _ in placement.items():
        n_core = (module_id, "core")
        if n_core in sync_wait_map:
            exec_time_map[(task_id, n_core)] += sync_wait_map[n_core]
    # --- 4) è®¡ç®— makespan ---
    makespan = compute_task_finish_time(
        task_id=task_id,
        agent_dag_edges=agent_dag_edges,
        exec_time_map=exec_time_map,
        edge_delay_map=edge_delay_map
    )
    # --- 5) èƒ½è€—è®¡ç®— ---
    exec_energy_J, comm_energy_J = 0.0, 0.0
    # (a) æ‰§è¡Œèƒ½è€—
    for (tid, module_id), info in placement.items():
        agent = agent_lookup[info["agent_id"]]
        dev = device_map[info["soft_device"]]
        r_cpu, _, r_gpu, _, _, _ = agent.r
        cpu_cap = float(getattr(dev.resource, "cpu", 0.0))
        gpu_cap = float(getattr(dev.resource, "gpu", 0.0))
        cpu_pow = float(getattr(dev.resource, "cpu_power", 0.0))
        gpu_pow = float(getattr(dev.resource, "gpu_power", 0.0))
        cpu_time = (r_cpu / cpu_cap) if cpu_cap > 0 else 0.0
        gpu_time = (r_gpu / gpu_cap) if gpu_cap > 0 else 0.0
        exec_energy_J += cpu_time * cpu_pow + gpu_time * gpu_pow

    # (b) é€šä¿¡èƒ½è€—
    for u, v, attr in task_graph.get_dependencies():
        du, dv = get_device_for_node(u), get_device_for_node(v)
        if du is None or dv is None or du == dv:
            continue
        src, dst = device_map[du], device_map[dv]
        _, _, ej = compute_transmission_delay(
            src=src, dst=dst,
            data_size_mb=attr.get("data_size", 1.0),
            bw_req=attr.get("bandwidth_req", 0.0),
            gw_matrix=gw_matrix
        )
        # æœ‰çº¿èƒ½è€—æƒé‡é™ä½
        if getattr(src, "conn_type", "wired") == "wired" and getattr(dst, "conn_type", "wired") == "wired":
            ej *= 0.1
        comm_energy_J += ej

    energy_bd = {
        "exec": float(exec_energy_J),
        "comm": float(comm_energy_J),
        "total": float(exec_energy_J + comm_energy_J),
    }

    return float(makespan), float(energy_bd["total"]), energy_bd


def _calculate_module_fitness_collab(
        nodes: set,
        G: nx.DiGraph,
        agent_lookup: Dict[int, AgentTemplate],
        cut_penalty_coef: float = 0.02,
) -> float:
    """
    è®¡ç®—â€œå€™é€‰æ¨¡å—â€çš„é€‚åº”åº¦ï¼ˆè¶Šå°è¶Šå¥½ï¼‰ã€‚
    - è½¯èƒ½åŠ›(C_soft)ä¸æ‰§è¡Œå™¨(C_act)ç¼ºå¤±ï¼šä¸å¯åä½œ => å¤§æƒ©ç½šï¼ˆUNSOLVABLE_MISMATCH_PENALTYï¼‰
    - ä¼ æ„Ÿèƒ½åŠ›(C_sense)ç¼ºå¤±ï¼šå¯è·¨æ¨¡å—åä½œ => å°æƒ©ç½šï¼ˆCOLLABORATION_PENALTY_PER_CAPï¼‰
    - cut æƒ©ç½šï¼šè½»å¾®æƒ©ç½šè·¨æ¨¡å—è¾¹ï¼Œé¼“åŠ±æŠŠå¼ºè€¦åˆå­å›¾æ”¾ä¸€èµ·
    - size æƒ©ç½šï¼šæ¨¡å—è¶Šå°è¶Šæƒ©ç½šï¼Œä¿ƒä½¿æ¨¡å—æ›´â€œé¥±æ»¡â€
    """
    if not nodes:
        return float('inf')

    # 1) èšåˆæ¨¡å—æ‰€éœ€èƒ½åŠ›
    C_sense, C_act, C_soft = get_module_capabilities(G, nodes)
    if not (C_sense or C_act or C_soft):
        # æ²¡èƒ½åŠ›éœ€æ±‚çš„â€œç©ºå£³â€ï¼Œé¿å…è¢«é€‰ä¸­
        return float('inf')

    # 2) åœ¨æ‰€æœ‰æ™ºèƒ½ä½“æ¨¡æ¿é‡Œæ‰¾â€œæƒ©ç½šæœ€å°â€çš„ä¸€ä¸ªï¼ˆä¹è§‚å‡è®¾æœ€ä½³åŒ¹é…ï¼‰
    best_agent_penalty = float('inf')
    for agent in agent_lookup.values():
        miss_soft = len(C_soft - agent.C_soft)  # ä¸å¯åä½œ
        miss_act = len(C_act - agent.C_act)  # ä¸å¯åä½œ
        miss_sense_collab = len(C_sense - agent.C_sense)  # å¯åä½œ

        penalty = (
                (miss_soft + miss_act) * UNSOLVABLE_MISMATCH_PENALTY +
                miss_sense_collab * COLLABORATION_PENALTY_PER_CAP
        )
        if penalty < best_agent_penalty:
            best_agent_penalty = penalty

    # 3) è½»é‡ cut æƒ©ç½šï¼šæ¨¡å—å¤–è¿æ¥è¶Šå¤šï¼Œæƒ©ç½šè¶Šå¤§ï¼ˆéå¸¸å°çš„ç³»æ•°ï¼Œé¿å…å–§å®¾å¤ºä¸»ï¼‰
    #   ä½ ä¹Ÿå¯ä»¥æŠŠå®ƒå…³æ‰ï¼šæŠŠ cut_penalty_coef è®¾ä¸º 0 å³å¯
    cut_edges = 0
    for u in nodes:
        # å‡ºè¾¹åˆ°æ¨¡å—å¤–
        for v in G.successors(u):
            if v not in nodes:
                cut_edges += 1
        # å…¥è¾¹æ¥è‡ªæ¨¡å—å¤–
        for v in G.predecessors(u):
            if v not in nodes:
                cut_edges += 1
    # å½’ä¸€åŒ–åˆ° [0,1] èŒƒå›´çš„ä¸€ä¸ªç²—ç•¥æŒ‡æ ‡
    possible_edges = max(1, len(nodes) * max(1, len(G.nodes) - len(nodes)))
    cut_penalty = cut_penalty_coef * (cut_edges / possible_edges)

    # 4) æ¨¡å—å¤§å°çš„åæ¯”æƒ©ç½šï¼ˆé¼“åŠ±æ›´é¥±æ»¡ï¼‰
    size_penalty = (1.0 / len(nodes)) * 0.1

    return best_agent_penalty + cut_penalty + size_penalty


def partition_with_greedy_algorithm(
        task_graph: TaskGraph,
        agent_lookup: Dict[int, AgentTemplate],
        max_module_size: int = 8
) -> List[set]:
    """
    ä½¿ç”¨â€œåä½œå‹å¥½â€çš„è´ªå¿ƒå¢é•¿ç®—æ³•å¯¹ä»»åŠ¡å›¾è¿›è¡Œåˆ’åˆ†ã€‚

    å·®å¼‚ç‚¹ï¼š
      - é€‚åº”åº¦å‡½æ•°æ”¹ä¸º _calculate_module_fitness_collabï¼ˆå…è®¸ä¼ æ„Ÿåä½œï¼‰
      - ç”Ÿé•¿æ—¶åªæ¥å—èƒ½æ˜¾è‘—é™ä½é€‚åº”åº¦çš„é‚»å±…ï¼Œå¦åˆ™åœæ­¢
    """
    G = task_graph.G
    unassigned = set(G.nodes())
    final_modules: List[set] = []

    while unassigned:
        # 1) é€‰ç§å­ï¼šä¼˜å…ˆ 'proc'
        proc_nodes = [n for n in unassigned if G.nodes[n].get("type") == "proc"]
        if proc_nodes:
            seed = random.choice(proc_nodes)
        else:
            # æ—  proc æ—¶éšä¾¿æŒ‘ä¸€ä¸ª
            seed = next(iter(unassigned))

        current = {seed}
        unassigned.remove(seed)

        # 2) è´ªå¿ƒç”Ÿé•¿
        while len(current) < max_module_size:
            # å€™é€‰ = å½“å‰æ¨¡å—æ‰€æœ‰é‚»å±… âˆ© æœªåˆ†é…
            neighbors = set()
            for n in current:
                neighbors.update(G.successors(n))
                neighbors.update(G.predecessors(n))
            candidates = neighbors & unassigned
            if not candidates:
                break

            # å½“å‰é€‚åº”åº¦
            base_fit = _calculate_module_fitness_collab(current, G, agent_lookup)
            best_fit = base_fit
            best_cand = None

            for c in candidates:
                tmp = current | {c}
                fit = _calculate_module_fitness_collab(tmp, G, agent_lookup)
                if fit < best_fit:
                    best_fit = fit
                    best_cand = c

            # è‹¥æ²¡æœ‰å€™é€‰èƒ½æ”¹è¿›ï¼Œåœæ­¢ç”Ÿé•¿
            if best_cand is None:
                break

            # æ¥çº³æœ€ä¼˜å€™é€‰
            current.add(best_cand)
            unassigned.remove(best_cand)

        final_modules.append(current)

    return final_modules


def match_agent_for_module(
        G: nx.DiGraph,
        nodes: set,
        agent_lookup: Dict[int, AgentTemplate],
        strict: bool = True
) -> Tuple[int, Dict[str, Any]]:
    C_sense, C_act, C_soft = get_module_capabilities(G, nodes)
    best_agent_id = None
    best_score = float("inf")
    best_info = {"perfect": False, "miss_soft": 0, "miss_act": 0, "miss_sense": 0}

    BIG = 1e6
    for aid, agent in agent_lookup.items():
        miss_soft = len(C_soft - agent.C_soft)
        miss_act = len(C_act - agent.C_act)
        miss_sense = len(C_sense - agent.C_sense)
        if strict and (miss_soft == 0 and miss_act == 0 and miss_sense == 0):
            return aid, {"perfect": True, "miss_soft": 0, "miss_act": 0, "miss_sense": 0}
        score = miss_soft * BIG + miss_act * BIG + miss_sense
        if score < best_score:
            best_score = score
            best_agent_id = aid
            best_info = {"perfect": (miss_soft == 0 and miss_act == 0 and miss_sense == 0),
                         "miss_soft": miss_soft, "miss_act": miss_act, "miss_sense": miss_sense}
    return best_agent_id, best_info


class TriPartPlacementEnv(gym.Env):
    """
    Tri-Part æ”¾ç½®ç¯å¢ƒï¼š
    - åŠ¨ä½œï¼šMultiDiscrete([num_devices] * (1 + K_s_max + K_a_max))
        [0]         : è®¡ç®—éƒ¨åˆ† -> è®¾å¤‡
        [1..Ks]     : æ¯ä¸ªâ€œå¿…éœ€ä¼ æ„Ÿèƒ½åŠ›â€ -> è®¾å¤‡
        [Ks+1..end] : æ¯ä¸ªâ€œå¿…éœ€é©±åŠ¨èƒ½åŠ›â€ -> è®¾å¤‡
    - è§‚æµ‹ï¼šDAGç‰¹å¾ã€è®¾å¤‡å‰©ä½™èµ„æºã€ä¸€äº›çº¦æŸç»Ÿè®¡ + ä¸‰ç±» mask
      (compute_mask, sense_mask[K_s_max, D], act_mask[K_a_max, D])
    - å¥–åŠ±ï¼ˆstepï¼‰ï¼š
        è¿›åº¦å¥–åŠ± R_PROGRESS
        - å»¶è¿Ÿ/å¸¦å®½è¿çº¦ï¼ˆæ¨¡å—é—´ã€ä¼ æ„Ÿâ†’ç®—åŠ›ã€ç®—åŠ›â†’é©±åŠ¨ï¼‰
        - é€šä¿¡/è®¡ç®—èƒ½è€—
      ï¼ˆç»ˆè¯„æ—¶ç”¨ makespan/æ€»èƒ½è€—/è¿çº¦è¿›è¡Œä¸€æ¬¡æ€§åŠ æ‰£ï¼‰
    """
    metadata = {"render_modes": []}

    def __init__(self, task_graphs, agent_lookup: Dict[int, AgentTemplate], device_map, gw_matrix,
                 K_s_max=3, K_a_max=3, seed=42,
                 task_num = 10,
                 # NEW â†“â†“â†“
                 max_module_size: int = 5,
                 min_module_size: int = 1,
                 lns_rounds: int = 300,
                 grasp_runs: int = 40,
                 grasp_rcl_k: int = 3,
                 grasp_weights: Dict[str, float] = GRASP_DEFAULT_WEIGHTS,
                 # NEW: é¢„è®¡ç®—è®¡åˆ’
                 precomputed_plans: Optional[Dict[int, Dict[str, Any]]] = None,
                 precomputed_plans_path: Optional[str] = None,
                 strict_fingerprint_check: bool = True,
                 # >>> æ–°å¢ï¼šç”¨äºå¯è¡Œæ€§åˆ¤å®šçš„é˜ˆå€¼ï¼ˆä¸ cSAC çš„ cost_limits å¯¹é½ï¼‰
                 constraint_limits: Optional[Dict[str, float]] = None,
                 sense_cap_quota_per_device: int = 2,  # æ¯å°è®¾å¤‡åŒä¸€ä¼ æ„Ÿèƒ½åŠ›æœ€å¤šåä½œæ¬¡æ•°Lï¼ˆé»˜è®¤ä¸º2ï¼‰
                 act_cap_quota_per_device: int = 1,  # æ‰§è¡Œå™¨é»˜è®¤ç‹¬å ï¼šåŒä¸€æ‰§è¡Œèƒ½åŠ›æ¯å°è®¾å¤‡åªèƒ½ç»‘å®š1æ¬¡
                 # åœ¨ __init__ å‚æ•°åˆ—è¡¨é‡ŒåŠ ï¼š
                 prune_by_latency: bool = False,
                 terminal_penalty: bool = True,
                 # >>> NEW: reward config
                 reward_mode: str = "penalty",  # "dense" | "paper"
                 paper_mid_alpha: float = 0.5,  # r_step = -(alpha*T + (1-alpha)*E)
                 paper_final_bonus_per_app: float = 50.0,  # +/- 50 * N (N = T = #apps)
                 early_terminate_on_violation: bool = False,  # å‘ç”Ÿç¡¬è¿è§„æ˜¯å¦ç«‹å³ -50N ç»ˆæ­¢
                 ):
        super().__init__()
        self.reward_mode = str(reward_mode).lower()
        self.paper_mid_alpha = float(paper_mid_alpha)
        self.paper_final_bonus_per_app = float(paper_final_bonus_per_app)
        self.early_terminate_on_violation = bool(early_terminate_on_violation)

        # __init__ ä½“å†…ï¼šæ ‡å‡†åŒ–æƒé‡
        def _to_weights(wlike):
            if isinstance(wlike, Weights):
                return wlike
            if isinstance(wlike, dict):
                return Weights(
                    w_module=wlike.get("w_module", 0.20),
                    w_interface=wlike.get("w_interface", 1.00),
                    w_redund=wlike.get("w_redund", 0.30),
                    w_collab=wlike.get("w_collab", 0.60),
                    w_balance=wlike.get("w_balance", 0.15),
                )
            return Weights()

        self.grasp_weights = _to_weights(grasp_weights)

        # ä¿å­˜æ–°å¼€å…³
        self.prune_by_latency = bool(prune_by_latency)
        self.terminal_penalty = bool(terminal_penalty)
        self.ep_cost_max = None
        self.ep_flags = None
        self.rng = np.random.default_rng(seed)


        loaded_tgs: list[TaskGraph] = []
        if task_graphs:  # æ¨¡å¼ A
            # å¦‚æœ task_count æŒ‡å®šäº†ï¼Œå°±ä¼˜å…ˆå– id åœ¨ [1..task_count] çš„ tgï¼›å¦åˆ™å…¨ç”¨
            if isinstance(task_num, int) and task_num > 0:
                # å…ˆæŒ‰ id æ’ä¸ªåºï¼Œç¡®ä¿ 1..task_count é¡ºåº
                sorted_tg = sorted(task_graphs, key=lambda tg: int(getattr(tg, "id", 10 ** 9)))
                keep_ids = set(range(1, task_num + 1))
                loaded_tgs = [tg for tg in sorted_tg if int(getattr(tg, "id", -1)) in keep_ids]
                # è‹¥ä¼ å…¥çš„ tg æ²¡æœ‰ id ä¿¡æ¯æˆ–æ•°é‡ä¸è¶³ï¼Œå°±é€€åŒ–ä¸ºç®€å•åˆ‡ç‰‡
                if len(loaded_tgs) == 0:
                    loaded_tgs = sorted_tg[:task_num]
            else:
                loaded_tgs = list(task_graphs)
        self.task_graphs = loaded_tgs
        self.T = len(self.task_graphs)  # ä»»åŠ¡æ•°
        self.agent_lookup = agent_lookup
        self.device_map = device_map
        self.gw_matrix = gw_matrix

        # NEW: ä¿å­˜ GRASP/LNS è¶…å‚
        self.max_module_size = max_module_size
        self.min_module_size = min_module_size
        self.lns_rounds = lns_rounds
        self.grasp_runs = grasp_runs
        self.grasp_rcl_k = grasp_rcl_k

        self.device_ids = sorted(device_map.keys())
        self.num_devices = len(self.device_ids)
        self.dev_id2idx = {d: i for i, d in enumerate(self.device_ids)}
        self.idx2dev = {i: d for d, i in self.dev_id2idx.items()}

        self.max_nodes = max(len(tg.G.nodes) for tg in self.task_graphs)
        self.K_s_max = K_s_max
        self.K_a_max = K_a_max
        self.num_heads = 1 + self.K_s_max + self.K_a_max
        self._soft_ema = 1.0  # ä»»ä½•æ­£æ•°èµ·æ­¥éƒ½è¡Œï¼Œé¿å…é™¤é›¶ï¼›ä¼šå¾ˆå¿«è‡ªé€‚åº”
        self.precomputed_plans = precomputed_plans
        self.precomputed_plans_path = precomputed_plans_path
        self.strict_fingerprint_check = strict_fingerprint_check
        if self.precomputed_plans is None and self.precomputed_plans_path is not None:
            # å»¶è¿ŸåŠ è½½
            self.precomputed_plans = load_partition_plans(self.precomputed_plans_path)

        self.modules_queue_by_task: Dict[int, List[Dict[str, Any]]] = {}
        self.current_modules_by_task: Dict[int, List[Dict[str, Any]]] = {}
        self.assigned_nodes_by_task: Dict[int, set] = {}

        self.curr_req_sense_by_task: Dict[int, List[int]] = {}
        self.curr_req_act_by_task: Dict[int, List[int]] = {}
        self.compute_mask_by_task: Dict[int, np.ndarray] = {}
        self.sense_mask_by_task: Dict[int, np.ndarray] = {}
        self.act_mask_by_task: Dict[int, np.ndarray] = {}
        self.LAT_TOL = 0.2  # å…è®¸ 5% è§„èŒƒåŒ–è¶…é¢ä»…ä½œä¸º shapingï¼Œä¸å½“ç¡¬è¿è§„
        self.BW_TOL = 0.2
        self.constraint_limits = constraint_limits or {"latency": self.LAT_TOL, "bandwidth": self.BW_TOL}
        # è§‚æµ‹
        self.observation_space = spaces.Dict({
            "device_resources": spaces.Box(0, 1, shape=(self.num_devices, 6), dtype=np.float32),
            "constraints": spaces.Box(0, 1, shape=(8,), dtype=np.float32),

            # âœ… å¤šä»»åŠ¡å½¢çŠ¶ï¼Œä¸ _obs() å®Œå…¨ä¸€è‡´
            "task_mask": spaces.Box(0, 1, shape=(self.T,), dtype=np.float32),
            "compute_mask": spaces.Box(0, 1, shape=(self.T, self.num_devices), dtype=np.float32),
            "sense_mask": spaces.Box(0, 1, shape=(self.T, self.K_s_max, self.num_devices), dtype=np.float32),
            "act_mask": spaces.Box(0, 1, shape=(self.T, self.K_a_max, self.num_devices), dtype=np.float32),
        })

        # è¿è¡ŒæœŸ
        self.current_task = None
        self.modules_queue: List[Dict[str, Any]] = []
        self.current_modules: List[Dict[str, Any]] = []
        self.assigned_nodes = set()
        self.step_count = 0
        self.resource_used = defaultdict(lambda: np.zeros(6, dtype=np.float32))
        self.curr_req_sense: List[int] = []
        self.curr_req_act: List[int] = []

        self.iot_indices = np.array(
            [i for i, did in enumerate(self.device_ids)
             if str(getattr(self.device_map[did], "type", "")).lower() == "device"],
            dtype=int
        )
        self.num_iot = int(len(self.iot_indices))
        self._iot_index_set = set(self.iot_indices.tolist())

        self._compute_mask = np.ones(self.num_devices, dtype=np.float32)
        self._sense_mask = np.ones((self.K_s_max, self.num_devices), dtype=np.float32)
        self._act_mask = np.ones((self.K_a_max, self.num_devices), dtype=np.float32)

        self._init_energy_denominators()

        self.sense_cap_quota_per_device = int(sense_cap_quota_per_device)
        self.act_cap_quota_per_device = int(act_cap_quota_per_device)

        # è¿è¡ŒæœŸå ç”¨è®¡æ•°ï¼šdevice_id -> {cap_id -> used_count}
        self.sense_cap_usage = defaultdict(lambda: defaultdict(int))
        self.act_cap_usage = defaultdict(lambda: defaultdict(int))

        # åŠ¨ä½œï¼šMultiDiscreteï¼ˆæ›´å¹²å‡€ï¼‰
        # ==== åŠ¨ä½œç©ºé—´ï¼šç¬¬ 0 ç»´ä¸ºä»»åŠ¡é€‰æ‹©å¤´ ====
        # __init__ é‡Œ
        self.action_space = spaces.MultiDiscrete(
            [self.num_devices] + [self.num_iot] * self.K_s_max + [self.num_iot] * self.K_a_max
        )

        self.violation_log = []  # ğŸš€ é€å›åˆè¿è§„è®°å½•ç¼“å†²
        # Episode çº§èƒ½è€—ç´¯è®¡ï¼ˆç„¦è€³ï¼‰
        self._episode_comm_J = 0.0
        self._episode_exec_J = 0.0
        self._progress_total_modules = sum(len(self.modules_queue_by_task.get(int(getattr(tg, "id", -1)), []))
                                           for tg in self.task_graphs)
        self._progress_done = 0
        self.STEP_TIME_COST = 0.01  # å¾®å°é€æ­¥æˆæœ¬ï¼ŒæŠ‘åˆ¶æ‹–æ­¥
        self._progress_total_modules = 0  # æ€»æ¨¡å—æ•°ï¼ˆæ¯æ¬¡ reset é‡ç®—ï¼‰
        self._progress_done = 0  # å·²æˆåŠŸæ¥çº³çš„æ¨¡å—æ•°
        self.np_random, _ = gym.utils.seeding.np_random(seed)
        self.action_space.seed(seed)
        # === è°ƒè¯•å¼€å…³ ===
        self.debug_level = 1  # 0=é™é»˜, 1=å…³é”®ä¿¡æ¯, 2=è¯¦ç»†
        self._last_obs = None
        # === è°ƒåº¦ï¼ˆç¯å¢ƒé€‰æ‹©å½“å‰è¦éƒ¨ç½²çš„ä»»åŠ¡ï¼‰===
        self.schedule_policy = "round_robin"  # å¯é€‰: "round_robin" | "random"
        self.task_ptr = -1
        self.active_tid = None  # å½“å‰æ¿€æ´»çš„ä»»åŠ¡id
        self.ep_cost_max = {"latency": 0.0, "bandwidth": 0.0}
        self.ep_cost_sum = {"latency": 0.0, "bandwidth": 0.0}  # å¯é€‰ï¼šç´¯è®¡
        self.ep_cost_cnt = 0  # å¯é€‰ï¼šæ­¥æ•°

    def _pick_next_task(self):
        """æŒ‰ç­–ç•¥é€‰ä¸‹ä¸€ä¸ªæœ‰å°±ç»ªæ¨¡å—çš„ä»»åŠ¡ï¼Œæ›´æ–° self.active_tidï¼›è‹¥éƒ½ç©ºåˆ™ç½® Noneã€‚"""
        tids = [int(getattr(tg, "id", -1)) for tg in self.task_graphs]
        if len(tids) == 0:
            self.active_tid = None
            return None
        if self.schedule_policy == "random":
            self.rng.shuffle(tids)
            for cand in tids:
                if len(self.modules_queue_by_task.get(cand, [])) > 0:
                    self.active_tid = cand
                    return cand
            self.active_tid = None
            return None
        # é»˜è®¤ï¼šround-robin
        for _ in range(len(tids)):
            self.task_ptr = (self.task_ptr + 1) % len(tids)
            cand = tids[self.task_ptr]
            if len(self.modules_queue_by_task.get(cand, [])) > 0:
                self.active_tid = cand
                return cand
        self.active_tid = None
        return None

    # === åŠ¨ä½œä¸æ©ç ä¸€è‡´æ€§æ£€æŸ¥ï¼ˆåªåšè°ƒè¯•ï¼Œä¸é˜»å¡ï¼‰ ===
    def _check_action_vs_mask(self, action: np.ndarray):
        try:
            nvec = self.action_space.nvec
            mask = self._flat_action_mask()
            offsets = np.cumsum([0] + list(nvec[:-1]))
            bad = []
            for h, val in enumerate(action):
                idx = int(offsets[h] + val)
                if idx >= mask.size or not mask[idx]:
                    bad.append((h, int(val)))
            if bad and self.debug_level >= 1:
                print(f"[WARN] Action not allowed by mask at heads: {bad}")
            return bad
        except Exception as e:
            if self.debug_level >= 1:
                print(f"[WARN] _check_action_vs_mask failed: {e}")
            return [("exception", -1)]

    # === æ©ç ç»Ÿè®¡ï¼ˆè¦†ç›–ç‡ & å¼‚å¸¸è¡Œï¼‰ ===
    def _mask_stats(self, obs: dict | None = None) -> dict:
        m = self._flat_action_mask()
        nvec = self.action_space.nvec
        offsets = np.cumsum([0] + list(nvec[:-1]))

        def seg(h): return m[offsets[h]: offsets[h] + nvec[h]]

        stats = {}
        # head 0: compute
        comp_seg = seg(0)
        stats["compute_true"] = int(comp_seg.sum())
        stats["compute_total"] = int(comp_seg.size)

        # heads 1..Ks: sense
        base = 1
        stats["sense_true_per_row"] = [int(seg(base + k).sum()) for k in range(self.K_s_max)]
        stats["sense_total_per_row"] = [int(nvec[base + k]) for k in range(self.K_s_max)]

        # heads Ks+1..end: act
        base2 = 1 + self.K_s_max
        stats["act_true_per_row"] = [int(seg(base2 + k).sum()) for k in range(self.K_a_max)]
        stats["act_total_per_row"] = [int(nvec[base2 + k]) for k in range(self.K_a_max)]

        stats["flat_true"] = int(m.sum())
        stats["flat_total"] = int(m.size)
        stats["flat_ratio"] = float(m.mean()) if m.size > 0 else 0.0
        return stats

    # åœ¨ç±»é‡Œæ–°å¢
    def action_masks(self) -> np.ndarray:
        # ç”¨å½“å‰ç¼“å­˜çš„è§‚æµ‹ï¼Œç¡®ä¿ä¸ç­–ç•¥è¾“å…¥ä¸€è‡´
        if self._last_obs is None:
            # è®­ç»ƒåˆšå¼€å§‹æ—¶ï¼ŒActionMasker ä¼šåœ¨ env.reset() åç«‹åˆ»è°ƒç”¨
            self._last_obs, _ = self.reset()
        return self._flat_action_mask(self._last_obs)

    # === æ©ç å½¢çŠ¶ä¸€è‡´æ€§æ£€æŸ¥ï¼ˆåœ¨ reset()/step() é‡Œå¶å°”è°ƒç”¨ï¼‰ ===
    def _check_masks_shapes(self, obs: dict):
        assert obs["task_mask"].shape == (self.T,), f"task_mask shape {obs['task_mask'].shape} != (T,)"
        assert obs["compute_mask"].shape == (self.T, self.num_devices), "compute_mask shape mismatch"
        assert obs["sense_mask"].shape == (self.T, self.K_s_max, self.num_devices), "sense_mask shape mismatch"
        assert obs["act_mask"].shape == (self.T, self.K_a_max, self.num_devices), "act_mask shape mismatch"
        # é¢å¤–ï¼šIoT ç´¢å¼•æœ‰æ•ˆ
        if self.num_iot > 0:
            assert np.all((self.iot_indices >= 0) & (self.iot_indices < self.num_devices)), "iot_indices out of range"

    # === ç»Ÿä¸€æ„é€ æ‰å¹³æ©ç ï¼ˆä¸ MultiDiscrete.nvec å®Œå…¨ä¸€è‡´ï¼‰===
    def _flat_action_mask(self, obs: dict | None = None) -> np.ndarray:
        # å¿½ç•¥ obs å‚æ•°ï¼Œç›´æ¥ç”¨å½“å‰ active ä»»åŠ¡çš„æ©ç 
        tid = self.active_tid
        # è‹¥æ‰€æœ‰ä»»åŠ¡éƒ½å®Œæˆ/æ— å¯éƒ¨ç½²ï¼Œè¿”å›å…¨ True ä»¥å…é‡‡æ ·å´©æºƒï¼ˆä¸‹ä¸€æ­¥å°±ä¼šç»ˆå±€ï¼‰
        if tid is None:
            return np.ones(int(self.action_space.nvec.sum()), dtype=bool)

        cm = self.compute_mask_by_task.get(tid, np.ones(self.num_devices, dtype=np.float32))
        sm = self.sense_mask_by_task.get(tid, np.ones((self.K_s_max, self.num_devices), dtype=np.float32))
        am = self.act_mask_by_task.get(tid, np.ones((self.K_a_max, self.num_devices), dtype=np.float32))

        parts = [cm > 0.5]
        if self.num_iot > 0:
            iot = self.iot_indices
            parts += [(sm[k, iot] > 0.5) for k in range(self.K_s_max)]
            parts += [(am[k, iot] > 0.5) for k in range(self.K_a_max)]
        mask = np.concatenate(parts, axis=0).astype(bool)

        # â€”â€” ä¿é™©ï¼šæ¯ä¸ª head è‡³å°‘ä¸€ä¸ª Trueï¼ˆMaskablePPO éœ€è¦ï¼‰
        seg_lens = [self.num_devices] + [self.num_iot] * self.K_s_max + [self.num_iot] * self.K_a_max
        off = 0
        for L in seg_lens:
            seg = mask[off:off + L]
            if L > 0 and seg.sum() == 0:
                seg[np.argmax(np.arange(L))] = True
            off += L
        expected = int(self.action_space.nvec.sum())
        assert mask.size == expected, f"mask.size={mask.size} != sum(nvec)={expected}"
        return mask

    def _load_or_build_modules_queue_for_task(self, tg: TaskGraph):
        """ç»™å•ä¸ªä»»åŠ¡æ„å»º/åŠ è½½ modules_queueã€‚"""
        task_id = getattr(tg, "id", None)
        if task_id is None:
            # å›é€€ GRASP/LNS
            plan = solve_stage1_partition_and_match(
                task_graph=tg, agent_lookup=self.agent_lookup, max_module_size=self.max_module_size,
                weights=(self.grasp_weights if isinstance(self.grasp_weights, Weights) else GRASP_DEFAULT_WEIGHTS)
            )
            q = [{"module_id": int(m["module_id"]), "nodes": set(m["nodes"]), "agent_id": int(m["agent_id"])} for m in
                 plan["modules"]]
            self.modules_queue_by_task[task_id] = q
            return

        # ä¼˜å…ˆè¯»å–é¢„è®¡ç®—
        if self.precomputed_plans is None and self.precomputed_plans_path is not None:
            self.precomputed_plans = load_partition_plans(self.precomputed_plans_path)

        if self.precomputed_plans:
            plan = self.precomputed_plans.get(int(task_id))
            self.modules_queue_by_task[task_id] = realize_plan_to_modules_queue(plan)
            return
            # if plan is not None:
            #     if self.strict_fingerprint_check:
            #         fp_now = _dag_fingerprint(tg.G)
            #         if plan.get("fingerprint") and plan["fingerprint"] != fp_now:
            #             # é‡æ–°æ„é€ 
            #             pass
            #         else:
            #             self.modules_queue_by_task[task_id] = realize_plan_to_modules_queue(plan)
            #             return

        # æ„é€ 
        plan = solve_stage1_partition_and_match(
            task_graph=tg, agent_lookup=self.agent_lookup, max_module_size=self.max_module_size,
            weights=(self.grasp_weights if isinstance(self.grasp_weights, Weights) else GRASP_DEFAULT_WEIGHTS)
        )
        self.modules_queue_by_task[task_id] = [
            {"module_id": int(m["module_id"]), "nodes": set(m["nodes"]), "agent_id": int(m["agent_id"])}
            for m in plan["modules"]
        ]

    def _init_energy_denominators(self):
        # ä¸ä½ ç°æœ‰ ACED ç¯å¢ƒç›¸åŒ
        try:
            max_data_mb = max(
                (attr.get("data_size", 0.0) for tg in self.task_graphs for _, _, attr in tg.get_dependencies()),
                default=1.0
            )
            max_data_mb = max(1.0, max_data_mb)
        except Exception:
            max_data_mb = 1.0
        self.comm_energy_norm = max(1e-6, COMM_ENERGY_PER_BIT_WIRED * max_data_mb * 8e6)

        try:
            max_cpu_need = max(float(tpl.r[0]) for tpl in self.agent_lookup.values())
            max_gpu_need = max(float(tpl.r[2]) for tpl in self.agent_lookup.values())
            min_cpu_cap, min_gpu_cap = float('inf'), float('inf')
            max_cpu_power, max_gpu_power = 0.0, 0.0
            for dev in self.device_map.values():
                res = dev.resource
                if getattr(res, "cpu", 0) > 0:
                    min_cpu_cap = min(min_cpu_cap, float(getattr(res, "cpu", 0)))
                    max_cpu_power = max(max_cpu_power, float(getattr(res, "cpu_power", 1.0)))
                if getattr(res, "gpu", 0) > 0:
                    min_gpu_cap = min(min_gpu_cap, float(getattr(res, "gpu", 0)))
                    max_gpu_power = max(max_gpu_power, float(getattr(res, "gpu_power", 1.0)))
            cpu_term = (max_cpu_need / max(1.0, min_cpu_cap)) * (max_cpu_power / 3600.0)
            gpu_term = (max_gpu_need / max(1.0, min_gpu_cap)) * (max_gpu_power / 3600.0)
            self.exec_energy_norm = max(1e-6, cpu_term + gpu_term)
        except Exception:
            self.exec_energy_norm = 1.0

    def _prune_compute_mask_by_latency(self, tid: int, tg: TaskGraph, cm: np.ndarray):
        """
        ç”¨å·²éƒ¨ç½²èŠ‚ç‚¹çš„è®¾å¤‡ï¼Œé¢„ä¼°å½“å‰æ¨¡å—è‹¥é€‰æ‹©æŸä¸ª compute_devï¼Œ
        æ˜¯å¦ä¼šå¯¼è‡´ ä¸å·²éƒ¨ç½²ç›¸é‚»èŠ‚ç‚¹ çš„è·¨æ¨¡å—è¾¹å‡ºç°æ˜æ˜¾å»¶è¿Ÿè¶…é¢ã€‚
        è‹¥æŸä¸ª compute_dev å¯¹ä»»æ„ç›¸å…³è¾¹çš„è§„èŒƒåŒ–å»¶è¿Ÿ > (LAT_TOL)ï¼Œåˆ™ cm[i]=0.
        """
        if cm is None or not np.any(cm > 0.5):
            return cm

        # æ”¶é›†å½“å‰ä»»åŠ¡é‡Œâ€œå·²éƒ¨ç½²â€çš„èŠ‚ç‚¹ -> è®¾å¤‡
        placed_dev_of = {}
        for mod in self.current_modules_by_task.get(tid, []):
            for n in mod["nodes"]:
                # æŸ¥è¿™ä¸ªèŠ‚ç‚¹åœ¨è¯¥å·²éƒ¨ç½²æ¨¡å—ä¸Šå¯¹åº”çš„è®¾å¤‡
                G = tg.G
                ntype = G.nodes[n].get("type", "proc")
                idx = G.nodes[n].get("idx")
                if ntype == "proc":
                    placed_dev_of[n] = mod["soft_device"]
                elif ntype == "sense":
                    placed_dev_of[n] = mod["sense_map"].get(idx)
                elif ntype == "act":
                    placed_dev_of[n] = mod["act_map"].get(idx)

        if not placed_dev_of:
            return cm  # æ²¡æœ‰ç›¸é‚»å·²éƒ¨ç½²èŠ‚ç‚¹ï¼Œä¸ä¿®å‰ª

        # æ‰¾å‡ºâ€œå½“å‰æ¨¡å—â€çš„èŠ‚ç‚¹é›†åˆï¼ˆæ¥è‡ªé˜Ÿé¦–æ¨¡å—ï¼‰
        q = self.modules_queue_by_task.get(tid, [])
        if not q:
            return cm
        cur_nodes = q[0]["nodes"]
        G = tg.G

        # é€ä¸ªå€™é€‰ compute_dev è¯•ç®—å®ƒä¸å·²éƒ¨ç½²é‚»å±…çš„é“¾è·¯å»¶è¿Ÿæ˜¯å¦æ˜æ˜¾è¶…é¢
        for i, did in enumerate(self.device_ids):
            if cm[i] < 0.5:
                continue
            # åªè¯„ä¼°å½“å‰æ¨¡å—ä¸­â€œproc èŠ‚ç‚¹â€ä½œä¸º compute_dev çš„æ‰¿è½½è€…
            # ä¸å·²éƒ¨ç½²é‚»å±…çš„è¾¹ï¼šcur_nodes â†” placed_nodes
            risky = False
            for u, v, attr in tg.get_dependencies():
                u_in = u in cur_nodes
                v_in = v in cur_nodes
                if u_in == v_in:
                    continue  # åªçœ‹è·¨æ¨¡å—
                other = v if u_in else u
                if other not in placed_dev_of:
                    continue

                # è®¾å¤‡å¯¹ (compute_dev, placed_dev)
                if u_in and G.nodes[u].get("type", "proc") == "proc":
                    du, dv = did, placed_dev_of[other]
                elif v_in and G.nodes[v].get("type", "proc") == "proc":
                    du, dv = placed_dev_of[other], did
                else:
                    # ä¸é procï¼ˆæ¯”å¦‚å½“å‰æ¨¡å—çš„ sense/actï¼‰åœ¨è¿™ä¸ªé˜¶æ®µå¾ˆéš¾å‡†ç¡®é¢„ä¼°ï¼Œè·³è¿‡
                    continue

                if du is None or dv is None or du == dv:
                    continue

                # è®¾å®šåˆç†é»˜è®¤
                u_type = G.nodes[u].get("type", "proc")
                v_type = G.nodes[v].get("type", "proc")
                data_mb = attr.get("data_size")
                bw_req = attr.get("bandwidth_req")
                lat_req = attr.get("latency_req")
                if data_mb is None:
                    data_mb = 0.5 if (u_type == "sense" and v_type == "proc") else (
                        0.1 if (u_type == "proc" and v_type == "act") else 1.0)
                if bw_req is None:
                    bw_req = 0.0
                if lat_req is None:
                    lat_req = 20.0 if ((u_type == "sense" and v_type == "proc") or (
                            u_type == "proc" and v_type == "act")) else 50.0

                dms, bw_act, _ = compute_transmission_delay(
                    src=self.device_map[du], dst=self.device_map[dv],
                    data_size_mb=data_mb, bw_req=bw_req, gw_matrix=self.gw_matrix
                )
                lat_norm = norm_latency(dms, lat_req)
                if lat_norm > self.LAT_TOL:
                    risky = True
                    break

            if risky:
                cm[i] = 0.0

        # è‹¥å…¨è¢«å‰”é™¤ï¼Œä¿ç•™ä¸€ä¸ªæœ€ä¸åçš„å€™é€‰å…œåº•ï¼Œé¿å…åŠ¨ä½œç©ºé—´å¡Œé™·
        if np.sum(cm > 0.5) == 0:
            feas = []
            for i, did in enumerate(self.device_ids):
                # è®¡ç®—ä¸€ä¸ªâ€œæœ€ä¸åâ€çš„ lat_norm ä½œä¸ºæ’åºä¾æ®
                worst = 0.0
                for u, v, attr in tg.get_dependencies():
                    u_in = u in cur_nodes
                    v_in = v in cur_nodes
                    if u_in == v_in:
                        continue
                    other = v if u_in else u
                    if other not in placed_dev_of:
                        continue
                    # åªè¯• proc ä¾§
                    if (u_in and G.nodes[u].get("type", "proc") != "proc") or \
                            (v_in and G.nodes[v].get("type", "proc") != "proc"):
                        continue
                    du = did
                    dv = placed_dev_of[other]
                    if du is None or dv is None or du == dv:
                        continue
                    dms, _, _ = compute_transmission_delay(
                        src=self.device_map[du], dst=self.device_map[dv],
                        data_size_mb=attr.get("data_size", 1.0),
                        bw_req=attr.get("bandwidth_req", 0.0),
                        gw_matrix=self.gw_matrix
                    )
                    lat_req = attr.get("latency_req", 50.0)
                    worst = max(worst, norm_latency(dms, lat_req))
                feas.append((worst, i))
            if feas:
                feas.sort(key=lambda x: x[0])
                cm[feas[0][1]] = 1.0  # é€‰ä¸€ä¸ªæœ€ä¸åçš„å…œåº•
        return cm

    # ğŸš€ æ–°å¢ï¼šç»Ÿä¸€çš„è¿è§„è®°å½•å™¨
    def _log_violation(self, tid: int, kind: str, payload: Dict[str, Any]):
        rec = {
            "step": int(self.step_count),
            "task_id": int(tid),
            "type": kind,
            **payload
        }
        self.violation_log.append(rec)

    def reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None):

        self.illegal_steps = 0  # æœ¬ EP ç¡¬è¿è§„æ­¥è®¡æ•°ï¼ˆéæ³•åŠ¨ä½œ/èƒ½åŠ›/èµ„æºä»»ä¸€è§¦å‘ï¼‰
        self.rejected_steps = 0  # æœ¬ EP è¢«æ‹’ç»è®¡æ•°ï¼ˆå¯é€‰ï¼‰

        self._soft_ema = 1.0  # ä»»ä½•æ­£æ•°èµ·æ­¥éƒ½è¡Œï¼Œé¿å…é™¤é›¶ï¼›ä¼šå¾ˆå¿«è‡ªé€‚åº”
        self.violation_log = []
        self.ep_flags = {"illegal": 0, "cap": 0, "resource": 0}
        self.ep_cost_max = {"latency": 0.0, "bandwidth": 0.0}
        if seed is not None:
            self.rng = np.random.default_rng(seed)

        self.step_count = 0
        self.resource_used = defaultdict(lambda: np.zeros(6, dtype=np.float32))
        self.sense_cap_usage.clear()
        self.act_cap_usage.clear()

        # ä¸ºæ¯ä¸ª task æ„å»º/åŠ è½½é˜Ÿåˆ—ã€æ¸…ç©ºçŠ¶æ€å¹¶å‡†å¤‡æ©ç 
        self.modules_queue_by_task = {}
        self.current_modules_by_task = {}
        self.assigned_nodes_by_task = {}
        self.curr_req_sense_by_task = {}
        self.curr_req_act_by_task = {}
        self.compute_mask_by_task = {}
        self.sense_mask_by_task = {}
        self.act_mask_by_task = {}

        for tg in self.task_graphs:
            tid = int(getattr(tg, "id", -1))
            self._load_or_build_modules_queue_for_task(tg)
            self.current_modules_by_task[tid] = []
            self.assigned_nodes_by_task[tid] = set()
            self._prepare_masks_for_task(tg)
        # ç»Ÿè®¡æœ¬å›åˆæ€»æ¨¡å—æ•°ï¼ˆåªç®—é˜Ÿåˆ—é‡Œçš„è®¡åˆ’æ¨¡å—ï¼‰
        self._progress_total_modules = sum(len(self.modules_queue_by_task.get(int(getattr(tg, "id", -1)), []))
                                           for tg in self.task_graphs)
        self._progress_done = 0
        # é€‰æ‹©é¦–ä¸ªå¯éƒ¨ç½²ä»»åŠ¡
        self.task_ptr = -1
        self._pick_next_task()
        obs = self._obs()
        self._last_obs = obs  # ç¼“å­˜
        try:
            self._check_masks_shapes(obs)
            if self.debug_level >= 2:
                print("[DBG reset] mask stats:", self._mask_stats(obs))
        except AssertionError as e:
            print("[ERR reset]", e)
        self.ep_cost_max["latency"] = 0.0
        self.ep_cost_max["bandwidth"] = 0.0
        self.ep_cost_sum["latency"] = 0.0
        self.ep_cost_sum["bandwidth"] = 0.0
        return obs, {}

    def _prepare_masks_for_task(self, tg: TaskGraph):
        tid = int(getattr(tg, "id", -1))
        q = self.modules_queue_by_task.get(tid, [])
        if not q:
            self.curr_req_sense_by_task[tid] = []
            self.curr_req_act_by_task[tid] = []
            self.compute_mask_by_task[tid] = np.ones(self.num_devices, dtype=np.float32)
            self.sense_mask_by_task[tid] = np.ones((self.K_s_max, self.num_devices), dtype=np.float32)
            self.act_mask_by_task[tid] = np.ones((self.K_a_max, self.num_devices), dtype=np.float32)
            return

        mod = q[0]
        agent = self.agent_lookup[mod["agent_id"]]
        req_s, req_a, req_soft = get_agent_capabilities(agent)
        req_s_list = sorted(list(req_s))[:self.K_s_max]
        req_a_list = sorted(list(req_a))[:self.K_a_max]

        self.curr_req_sense_by_task[tid] = req_s_list
        self.curr_req_act_by_task[tid] = req_a_list

        # âœ… ä¿®æ­£ï¼šç¬¬äºŒä¸ªå‚æ•°åº”ä¸º agent_id
        self.compute_mask_by_task[tid] = self._build_compute_mask(req_soft, agent_id=mod["agent_id"])
        if self.prune_by_latency:
            self.compute_mask_by_task[tid] = self._prune_compute_mask_by_latency(tid, tg,
                                                                                 self.compute_mask_by_task[tid])

        self.sense_mask_by_task[tid] = self._build_cap_mask(req_s_list, "sense")
        self.act_mask_by_task[tid] = self._build_cap_mask(req_a_list, "act")

    def _build_compute_mask(self, req_soft: set, agent_id: int) -> np.ndarray:
        mask = np.ones(self.num_devices, dtype=np.float32)
        needed_r6 = np.array(self.agent_lookup[agent_id].r, dtype=np.float32)
        need4 = needed_r6[[1, 3, 4, 5]]
        for i, did in enumerate(self.device_ids):
            dev = self.device_map[did]
            # AFTER:
            if len(req_soft - dev.soft_cap) > 0:
                mask[i] = 0.0
                continue
            # èµ„æº
            # å››ç»´èµ„æºæ£€æŸ¥ï¼ˆä¸ step ä¿æŒä¸€è‡´ï¼‰
            used4 = self.resource_used[did][[1, 3, 4, 5]]
            cap4 = self._cap4(dev)
            if np.any(used4 + need4 > cap4 + 1e-6):
                mask[i] = 0.0

        return mask

    def _build_cap_mask(self, cap_list: List[int], cap_type: str) -> np.ndarray:
        K = self.K_s_max if cap_type == "sense" else self.K_a_max
        mask = np.ones((K, self.num_devices), dtype=np.float32)  # é»˜è®¤å…¨ 1ï¼ˆæœªç”¨ä½ï¼‰
        for k in range(K):
            if k >= len(cap_list):
                continue  # æœªä½¿ç”¨ä½ä¿æŒå…¨ 1
            cap = cap_list[k]
            # å…ˆç½® 0ï¼Œå†å¡«å¯è¡Œè®¾å¤‡ä¸º 1
            mask[k, :] = 0.0

            for i, did in enumerate(self.device_ids):
                # âœ… sense/act åªèƒ½å» IoT è¡Œ
                if cap_type in ("sense", "act") and (i not in self._iot_index_set):
                    continue

                dev = self.device_map[did]
                has = cap in (dev.sense_cap if cap_type == "sense" else dev.act_cap)
                if not has:
                    continue

                usage = (self.sense_cap_usage if cap_type == "sense" else self.act_cap_usage)[did][cap]
                quota = (self.sense_cap_quota_per_device if cap_type == "sense" else self.act_cap_quota_per_device)
                if usage < quota:
                    mask[k, i] = 1.0
                    # è°ƒè¯•ï¼šè¿™ä¸€è¡Œå®Œå…¨ 0ï¼Œè¯´æ˜è¿™ä¸ªèƒ½åŠ›åœ¨ IoT ä¸Šæ²¡äººèƒ½æ¥ or é…é¢è€—å°½
            if mask[k].max() < 0.5:
                # è‹¥ IoT ä¸Šâ€œæœ‰æ­¤capçš„è®¾å¤‡â€å­˜åœ¨ï¼Œåªæ˜¯é…é¢è€—å°½ï¼Œåˆ™é€‰ä¸€ä¸ªèµ„æºæœ€æ¾çš„ IoT ä½œä¸ºå…œåº•
                cand = []
                for i, did in enumerate(self.device_ids):
                    if i not in self._iot_index_set:
                        continue
                    dev = self.device_map[did]
                    has = cap in (dev.sense_cap if cap_type == "sense" else dev.act_cap)
                    if has:
                        cand.append(i)

                if len(cand) > 0:
                    # é€‰ä¸€ä¸ªâ€œæœ€æ¾â€çš„è®¾å¤‡å…œåº•ï¼Œé¿å…è¯¥headå…¨0
                    def slack(i):
                        did = self.device_ids[i]
                        used4 = self.resource_used[did][[1, 3, 4, 5]]
                        cap4 = self._cap4(self.device_map[did])
                        return float(np.sum((cap4 - used4) / (cap4 + 1e-6)))

                    best_i = max(cand, key=slack)
                    mask[k, best_i] = 1.0
                else:
                    # çœŸä¸å¯è¡Œï¼šIoTä¸Šä¸å­˜åœ¨è¯¥capï¼Œç•™å…¨0ï¼Œå¹¶åœ¨ task å±‚åšå±è”½ï¼ˆè§ä¸‹ï¼‰
                    if self.debug_level >= 1:
                        print(f"[DEBUG] truly infeasible {cap_type} cap={cap}: no IoT has this capability.")

        return mask

    def _obs(self):
        # è®¾å¤‡èµ„æº
        dev_feats = np.zeros((self.num_devices, 6), dtype=np.float32)
        for i, did in enumerate(self.device_ids):
            res = self.device_map[did].resource
            initial = np.array([
                getattr(res, "cpu", 0.0), getattr(res, "num", 0.0),
                getattr(res, "gpu", 0.0), getattr(res, "gpu_mem", 0.0),
                getattr(res, "ram", 0.0), getattr(res, "disk", 0.0)
            ], dtype=np.float32)
            remain = initial - self.resource_used[did]
            denom = np.maximum(1.0, initial)
            dev_feats[i, :] = remain / denom

        # çº¦æŸ/è¿›åº¦ï¼ˆç®€å•å…¨å±€æŒ‡æ ‡ï¼‰
        total_nodes = sum(len(tg.G.nodes) for tg in self.task_graphs)
        placed_nodes = 0
        for tg in self.task_graphs:
            tid = int(getattr(tg, "id", -1))
            placed_nodes += len(self.assigned_nodes_by_task.get(tid, set()))
        constraints = np.array([
            0.0,
            placed_nodes / max(1, total_nodes),
            0.0,
            (sum(len(self.current_modules_by_task.get(int(getattr(tg, "id", -1)), [])) for tg in self.task_graphs)) /
            max(1, sum(len(self.modules_queue_by_task.get(int(getattr(tg, "id", -1)), [])) +
                       len(self.current_modules_by_task.get(int(getattr(tg, "id", -1)), []))
                       for tg in self.task_graphs)),
            # ä¸‹é¢ä¸¤ä¸ªå ä½ï¼šå¯ä»¥åšæˆå¹³å‡çš„æ„ŸçŸ¥/æ‰§è¡Œæ¯”ä¾‹
            0.0, 0.0,
            self.step_count / max(1, total_nodes * 5),
            0.0
        ], dtype=np.float32)

        # å¤šä»»åŠ¡æ©ç æ‹¼æ¥
        task_ids = [int(getattr(tg, "id", -1)) for tg in self.task_graphs]
        T = len(task_ids)
        task_mask = np.zeros((T,), dtype=np.float32)
        compute_mask = np.zeros((T, self.num_devices), dtype=np.float32)
        sense_mask = np.ones((T, self.K_s_max, self.num_devices), dtype=np.float32)
        act_mask = np.ones((T, self.K_a_max, self.num_devices), dtype=np.float32)

        for t_idx, tid in enumerate(task_ids):
            q = self.modules_queue_by_task.get(tid, [])
            task_mask[t_idx] = 1.0 if len(q) > 0 else 0.0
            cm = self.compute_mask_by_task.get(tid)
            sm = self.sense_mask_by_task.get(tid)
            am = self.act_mask_by_task.get(tid)
            if cm is not None:
                compute_mask[t_idx, :] = cm
            if sm is not None:
                sense_mask[t_idx, :, :] = sm
            if am is not None:
                act_mask[t_idx, :, :] = am

        return {
            "device_resources": dev_feats,
            "constraints": constraints,
            "task_mask": task_mask,
            "compute_mask": compute_mask,
            "sense_mask": sense_mask,
            "act_mask": act_mask,
        }

    def _all_tasks_done(self) -> bool:
        return all(len(q) == 0 for q in self.modules_queue_by_task.values())

    def _explain_cap_row(self, cap: int, cap_type: str):
        rows = []
        usage = self.sense_cap_usage if cap_type == "sense" else self.act_cap_usage
        quota = self.sense_cap_quota_per_device if cap_type == "sense" else self.act_cap_quota_per_device
        for did in self.device_ids:
            dev = self.device_map[did]
            has_cap = cap in (dev.sense_cap if cap_type == "sense" else dev.act_cap)
            used = usage[did][cap]
            reason = (
                "device_lacks_cap" if not has_cap
                else ("quota_exhausted" if used >= quota else "OK")
            )
            rows.append({
                "device_id": int(did),
                "has_cap": bool(has_cap),
                "used": int(used),
                "quota": int(quota),
                "reason": reason
            })
        return rows

    def _scan_infra_availability(self):
        missing = {"sense": [], "act": []}
        iot_devs = [self.device_map[self.device_ids[i]] for i in self.iot_indices]

        for cap in self.curr_req_sense:
            if not any(cap in dev.sense_cap for dev in iot_devs):
                missing["sense"].append(int(cap))
        for cap in self.curr_req_act:
            if not any(cap in dev.act_cap for dev in iot_devs):
                missing["act"].append(int(cap))
        return missing

    def _finalize_all_tasks(self):
        info = {}
        try:
            total_mk, total_energy = 0.0, 0.0
            energy_bd_all = {"exec": 0.0, "comm": 0.0, "total": 0.0}

            # ==== æ±‡æ€»æ¯ä¸ªä»»åŠ¡çš„ makespan/èƒ½è€— ====
            for tg in self.task_graphs:
                tid = int(getattr(tg, "id", -1))
                placement = {(tid, m['module_id']): m for m in self.current_modules_by_task.get(tid, [])}
                if len(placement) == 0:
                    continue
                mk, en, ebd = evaluation_func_rl(placement, tg, self.agent_lookup, self.device_map, self.gw_matrix)
                total_mk += float(mk)
                total_energy += float(en)
                energy_bd_all["exec"] += float(ebd.get("exec", 0.0))
                energy_bd_all["comm"] += float(ebd.get("comm", 0.0))
                energy_bd_all["total"] += float(ebd.get("total", 0.0))

            # ==== è½¯/ç¡¬çº¦æŸç»Ÿè®¡ ====
            lim_lat = float(self.constraint_limits.get("latency", self.LAT_TOL))
            lim_bw = float(self.constraint_limits.get("bandwidth", self.BW_TOL))
            hard_ok = (self.ep_flags["illegal"] == 0 and self.ep_flags["cap"] == 0 and self.ep_flags["resource"] == 0)
            soft_ok = (self.ep_cost_max["latency"] <= lim_lat) and (self.ep_cost_max["bandwidth"] <= lim_bw)
            feasible = bool(hard_ok)

            over_lat = max(0.0, self.ep_cost_max["latency"] - lim_lat)
            over_bw = max(0.0, self.ep_cost_max["bandwidth"] - lim_bw)
            soft_over = over_lat + over_bw
            hard_cnt = float(self.ep_flags["illegal"] + self.ep_flags["cap"] + self.ep_flags["resource"])
            all_done, dep_detail = self.check_all_modules_deployed()
            completion = float(self._progress_done) / max(1, self._progress_total_modules)  # [0,1]

            self._soft_ema = 0.95 * getattr(self, "_soft_ema", 1.0) + 0.05 * max(soft_over, 1e-6)

            # ==== è®°å½• info ====
            info.update({
                "status": "success_feasible" if feasible else "infeasible",
                "makespan": float(total_mk),
                "energy": float(total_energy),
                "energy_breakdown": {k: float(v) for k, v in energy_bd_all.items()},
                "feasible": feasible,
                "max_latency_cost": self.ep_cost_max["latency"],
                "max_bandwidth_cost": self.ep_cost_max["bandwidth"],
                "limits": {"latency": lim_lat, "bandwidth": lim_bw},
                "hard_violations": dict(self.ep_flags),
                "violation_log": list(self.violation_log),
                "completion": completion,
                "soft_over": {"lat": over_lat, "bw": over_bw, "sum": soft_over},
                "all_modules_deployed": bool(all_done),
                "deployment_detail": dep_detail,
            })

            # ==== å½’ä¸€åŒ–åŸºå‡†ï¼ˆEMAï¼‰====
            self._mk_ema = 0.95 * getattr(self, "_mk_ema", max(1e-6, total_mk)) + 0.05 * max(1e-6, total_mk)
            self._en_ema = 0.95 * getattr(self, "_en_ema", max(1e-6, total_energy)) + 0.05 * max(1e-6, total_energy)
            mk_norm = float(total_mk) / max(1e-6, self._mk_ema)
            en_norm = float(total_energy) / max(1e-6, self._en_ema)

            # ==== è½¯çº¦æŸï¼ˆç»Ÿä¸€å£å¾„ï¼šéƒ½ç”¨â€œå½’ä¸€ + åŒä¸€å¸¸æ•°â€ï¼‰====
            # ä½ å‰é¢å·²ç»æœ‰ï¼šover_lat, over_bw, soft_over = over_lat + over_bw
            # ç”¨ EMA åšç¨³å®šå½’ä¸€ï¼ˆä¸ step çš„ç»Ÿè®¡åˆ†å¸ƒä¸€è‡´ï¼‰
            self._soft_ema = 0.95 * getattr(self, "_soft_ema", max(1e-3, soft_over)) + 0.05 * max(1e-3, soft_over)
            soft_norm = float(soft_over / max(1e-6, self._soft_ema))
            # ä¸ºé¿å…å°–å³°ï¼Œåšæˆªæ–­ï¼ˆHuber é£æ ¼ï¼‰
            soft_norm = float(min(soft_norm, 3.0))

            # ==== ç»ˆå±€æƒé‡ï¼ˆå»ºè®®æ”¾åˆ° __init__ å¯é…ç½®ï¼‰====
            W_MK = getattr(self, "W_FINAL_MAKESPAN", 12.0)
            W_EN = getattr(self, "W_FINAL_ENERGY", 2.5)
            K_LEFT = getattr(self, "K_LEFTOVER", 20.0)
            K_HARD = getattr(self, "K_HARD_VIOL", 0.2)

            # æ˜¯å¦åœ¨ episode å†å¯¹ soft_over è®¡ç½šï¼š
            # - å¦‚æœ step å·²ç»å¯¹ lat/bw åšäº† shapingï¼ˆä½ çš„æƒ…å†µï¼‰ï¼Œè¿™é‡Œå»ºè®®ç”¨ä¸€ä¸ª **è¾ƒå°** çš„ç»ˆå±€è½¯æƒ©ç½šï¼ˆæˆ–ä»…é€šè¿‡ bonus gating ä½“ç°ï¼‰
            USE_EP_SOFT_PENALTY = getattr(self, "USE_EP_SOFT_PENALTY", True)
            K_SOFT = getattr(self, "K_SOFT_OVER_EP", 1)  # æ¯”åŸæ¥çš„ K_SOFT_OVER å°ä¸€äº›

            # âœ… ä¸è¦è¦†ç›– feasibleï¼æ²¿ç”¨ä¸Šé¢æ ¹æ®é™å€¼ç®—å‡ºçš„ feasible
            # feasible = True  # â† åˆ æ‰è¿™è¡Œ

            # ç»ˆå±€å¥–åŠ±ï¼šbonus åªåœ¨â€œå®Œæˆä¸”å¯è¡Œâ€æ—¶å‘æ”¾
            FINISH_BONUS = 0
            base_bonus = (FINISH_BONUS if (completion >= 0.999 and feasible) else -FAIL_PENALTY)

            soft_term = (K_SOFT * soft_norm) if USE_EP_SOFT_PENALTY else 0.0

            final_reward = (
                    - W_MK * mk_norm
                    - W_EN * en_norm
                    - K_LEFT * (1.0 - completion)
                    - 10 * hard_cnt
                    - 50*self.ep_cost_sum["latency"]
                    - self.ep_cost_sum["bandwidth"]
                    + base_bonus
            )

            # ç»Ÿä¸€ infoï¼šä¿æŒâ€œæ˜¾ç¤ºç”¨ penaltyâ€ä¸ reward åŒå£å¾„ï¼ˆæ–¹ä¾¿å¯¹é½ï¼‰
            info["penalty"] = float(
                W_MK * mk_norm
                + W_EN * en_norm
                + K_LEFT * (1.0 - completion)
                + K_HARD * hard_cnt
                + (K_SOFT * soft_norm if USE_EP_SOFT_PENALTY else 0.0)
            )

            # ==== å†™å…¥ episode è¯¦ç»†åˆ†è§£ï¼Œä¾¿äºå¯è§†åŒ– ====
            info["epinfo"] = {
                "r_final": float(final_reward),  # ä½ è®¾è®¡çš„â€œç»ˆå±€ä¸€æ­¥â€å¥–åŠ±
                "mk": float(total_mk),
                "E": float(total_energy),
                "soft_over": float(soft_over),
                "comp": float(completion),
                "hard": int(hard_cnt),
                "lat_sum": float(self.ep_cost_sum["latency"]),
            }

            # è¿”å›ä¸‹ä¸€è§‚æµ‹ï¼ˆGym æ¥å£éœ€è¦ï¼‰ï¼Œä½†å·²ç»ˆæ­¢
            return self._obs(), float(final_reward), True, False, info

        except Exception as e:
            info.update({
                "status": f"fail_eval_error: {e}",
                "makespan": -1.0, "energy": -1.0,
                "penalty": float("inf"),
            })
            final_reward = -getattr(self, "FAIL_PENALTY", 2.0)
            info["episode"] = {"r": float(final_reward), "l": int(self.step_count)}
            return self._obs(), float(final_reward), True, False, info

    def _refresh_all_masks(self):
        for tg in self.task_graphs:
            self._prepare_masks_for_task(tg)


    def step(self, action: np.ndarray):

        """
        è§£ç å¤šå¤´åŠ¨ä½œ -> ä¿®æ­£ä»»ä½•â€œmask ä¸å¯è¡Œâ€çš„é€‰æ‹© ->
        æ„é€  module_assignment ->
        è®¡ç®— step å¥–åŠ±ï¼ˆå«ä¸‰ç±»é“¾è·¯ï¼‰-> æ¥çº³å¹¶æ›´æ–°èµ„æº ->
        è‹¥å®Œæˆ/æˆªæ–­ï¼šåšä¸€æ¬¡â€œå…¨å±€ç»ˆè¯„â€ï¼ˆmakespan/èƒ½è€—/è¿çº¦ï¼‰
        """
        R_PROGRESS = 1.0
        W_COMM_ENERGY = 1.0
        W_EXEC_ENERGY = 1.0

        # è¿æ³•åŠ¨ä½œ/èƒ½åŠ›/èµ„æºçš„å•æ­¥æƒ©ç½šä¸æå‰ç»ˆæ­¢ç­–ç•¥
        P_ILLEGAL = 5.0  # å•æ­¥éæ³•åŠ¨ä½œï¼ˆæ¯”å¦‚ head é€‰æ‹©åˆ° mask=0ï¼‰çš„æƒ©ç½šåŸºæ•°
        P_CAP = 10.0  # èƒ½åŠ›ä¸åŒ¹é…ï¼ˆsoft/sense/act ç¼ºå¤±ï¼‰æƒ©ç½šåŸºæ•°
        P_RESOURCE = 10.0  # èµ„æºè¶Šç•Œï¼ˆnum/gpu_mem/ram/diskï¼‰æƒ©ç½šåŸºæ•°
        MAX_ILLEGAL_STEPS = 25  # å•å›åˆæœ€å¤šå…è®¸å¤šå°‘æ¬¡â€œç¡¬è¿è§„æ­¥â€
        terminate_on_illegal = True  # è¾¾åˆ°é˜ˆå€¼æ˜¯å¦æå‰ç»ˆæ­¢

        if self.debug_level >= 2:
            self._check_action_vs_mask(action)
        self.step_count += 1
        # å¦‚æœå…¨ä»»åŠ¡éƒ½å®Œæˆï¼Œç›´æ¥ç»ˆå±€
        if self._all_tasks_done():
            return self._finalize_all_tasks()

        # è‹¥å½“å‰ active ä»»åŠ¡ä¸ºç©ºæˆ–å…¶é˜Ÿåˆ—ä¸ºç©ºï¼Œåˆ™åˆ‡åˆ°ä¸‹ä¸€ä¸ª
        if (self.active_tid is None) or (len(self.modules_queue_by_task.get(self.active_tid, [])) == 0):
            self._pick_next_task()
            if (self.active_tid is None):
                return self._finalize_all_tasks()

        tid = self.active_tid
        tg = next(t for t in self.task_graphs if int(getattr(t, "id", -1)) == tid)
        queue = self.modules_queue_by_task[tid]
        if not queue:
            self._pick_next_task()
            if (self.active_tid is None):
                return self._finalize_all_tasks()
            tid = self.active_tid
            tg = next(t for t in self.task_graphs if int(getattr(t, "id", -1)) == tid)
            queue = self.modules_queue_by_task[tid]
            if not queue:
                return self._finalize_all_tasks()

        action = np.asarray(action, dtype=int)

        # âœ… ä»â€œè¯¥ä»»åŠ¡â€çš„é˜Ÿåˆ—é‡Œå¼¹å‡º
        mod = queue.pop(0)
        aid = mod["agent_id"]
        agent = self.agent_lookup[aid]

        # æ©ç å–è¯¥ä»»åŠ¡çš„
        cm = self.compute_mask_by_task[tid]
        sm = self.sense_mask_by_task[tid]
        am = self.act_mask_by_task[tid]
        # è§£ç å¤šå¤´åŠ¨ä½œ
        # è§£ç å¹¶ä¿®æ­£éæ³•åŠ¨ä½œ
        # â€”â€” è§£ç ï¼ˆæ— ä»»åŠ¡å¤´ï¼‰â€”â€”
        illegal_caps, illegal_details = 0, []
        compute_dev = -1

        # head 0: compute
        comp_idx = int(np.clip(action[0], 0, self.num_devices - 1))
        if (cm > 0.5).sum() == 0 or (cm[comp_idx] < 0.5):
            illegal_caps += 1
            illegal_details.append({"type": "compute"})
        else:
            compute_dev = self.idx2dev[comp_idx]

        # ä¼ æ„Ÿå¤´
        sense_map, act_map = {}, {}

        base = 1  # åŠ¨ä½œç´¢å¼•ï¼š0=task, 1=compute_head

        req_s = self.curr_req_sense_by_task.get(tid, [])
        for k in range(self.K_s_max):
            if k >= len(req_s):  # æœªä½¿ç”¨ä½
                continue
            cap = req_s[k]
            local = int(np.clip(action[base + k], 0, self.num_iot - 1))
            idx = int(self.iot_indices[local]) if self.num_iot > 0 else -1
            if (idx < 0) or (sm[k, idx] < 0.5):
                illegal_caps += 1
                illegal_details.append({"type": "sense", "cap": int(cap)})
            else:
                sense_map[cap] = self.idx2dev[idx]

        # é©±åŠ¨å¤´
        base2 = base + self.K_s_max
        req_a = self.curr_req_act_by_task.get(tid, [])
        for k in range(self.K_a_max):
            if k >= len(req_a):  # æœªä½¿ç”¨ä½
                continue
            cap = req_a[k]
            local = int(np.clip(action[base2 + k], 0, self.num_iot - 1))
            idx = int(self.iot_indices[local]) if self.num_iot > 0 else -1
            if (idx < 0) or (am[k, idx] < 0.5):
                illegal_caps += 1
                illegal_details.append({"type": "act", "cap": int(cap)})
            else:
                act_map[cap] = self.idx2dev[idx]
        # ç»„è£…
        m = {
            "nodes": set(mod["nodes"]),
            "agent_id": aid,
            "soft_device": compute_dev,
            "sense_map": sense_map,
            "act_map": act_map,
            "module_id": len(self.current_modules_by_task[tid]),
        }
        _, step_costs, step_details = self._tri_part_step_reward_for_task(tid, tg, m, illegal_caps)

        # åœ¨ step() ä¸­ï¼Œè®¡ç®— rewardã€step_costsã€step_details ä¹‹åï¼š
        hard_violation = (
                step_costs.get("illegal_caps", 0.0) > 0.0 or
                step_costs.get("cap_violation", 0.0) > 0.0 or
                step_costs.get("resource_violation", 0.0) > 0.0
        )

        if hard_violation:
            # âŒ ä¸æ¥çº³ï¼šæŠŠæ¨¡å—æ”¾å›é˜Ÿåˆ—å¼€å¤´
            # self.modules_queue_by_task[tid].insert(0, mod)
            self.modules_queue_by_task[tid].append(mod)
            # åˆ·æ–°æ©ç å¹¶åˆ‡æ¢ä¸‹ä¸€ä¸ªä»»åŠ¡ï¼Œç”Ÿæˆä¸‹ä¸€çŠ¶æ€è§‚æµ‹
            self._refresh_all_masks()
            obs = self._obs()
            self._last_obs = obs
            # === PPOç”¨ï¼šæŒ‰è¿è§„å¼ºåº¦ç»™è´Ÿå¥–åŠ± ===
            g_illegal = float(step_costs.get("illegal_caps", 0.0))  # å¤šå°‘ä¸ªå­ä½éæ³•
            g_cap = float(step_costs.get("cap_violation", 0.0))  # ç¼ºå¤±èƒ½åŠ›è®¡æ•°
            g_res = float(step_costs.get("resource_violation", 0.0))  # èµ„æºè¶Šç•Œ(0/1)

            self.ep_flags["illegal"] += g_illegal
            self.ep_flags["cap"] += g_cap
            self.ep_flags["resource"] += g_res
            penalty = (
                    P_ILLEGAL * g_illegal +
                    P_CAP * g_cap +
                    P_RESOURCE * g_res
            )
            # å°‘é‡æ—¶é—´æˆæœ¬ï¼Œé¿å… agent åœ¨è¿è§„çŠ¶æ€ç©ºè½¬
            reward = -(penalty + 0.5 * self.STEP_TIME_COST)
            # è¦†ç›–å¥–åŠ±ï¼šæ‹’ç»ä¸è®¸æ‹¿è¿›åº¦å¥–åŠ±
            info = {
                "costs": step_costs, "violations_this_step": step_details,
                "rejected": True, "accepted": False,
                "rew_terms": {"penalty": float(penalty)},
                "mask_stats": self._mask_stats()
            }
            if self.debug_level >= 1:
                info["mask_stats"] = self._mask_stats(self._last_obs) if hasattr(self, "_last_obs") else {}

                # âœ… è¿”å›ç¼“å­˜çš„è§‚æµ‹ï¼Œä¿æŒä¸ ActionMasker åŒæ­¥
            return self._last_obs if hasattr(self, "_last_obs") and self._last_obs is not None else self._obs(), \
                float(reward), False, False, info

        # æ¥çº³ & æ›´æ–°
        self.current_modules_by_task[tid].append(m)
        self.assigned_nodes_by_task[tid].update(mod["nodes"])
        self.resource_used[compute_dev] += np.array(agent.r, dtype=np.float32)
        self._progress_done += 1
        progress_delta = 1.0 / max(1, self._progress_total_modules)
        # â€”â€” æ–°å¢ï¼šæ›´æ–°èƒ½åŠ›å ç”¨è®¡æ•°ï¼ˆç”¨äºåç»­maskï¼‰ â€”â€”
        for cap, dev_id in sense_map.items():
            if dev_id is not None:
                self.sense_cap_usage[dev_id][cap] += 1
        for cap, dev_id in act_map.items():
            if dev_id is not None:
                self.act_cap_usage[dev_id][cap] += 1

        # ğŸ” å…³é”®ï¼šæ›´æ–°åç»Ÿä¸€åˆ·æ–°æ‰€æœ‰ä»»åŠ¡çš„ mask
        self._refresh_all_masks()

        obs = self._obs()
        self.last_obs = obs
        terminated = self._all_tasks_done()
        # ç»™äºˆæ›´å¤šæ­¥æ•°ä½™é‡
        max_steps = int(1 * sum(len(tg.G.nodes) for tg in self.task_graphs))
        truncated = (self.step_count >= max_steps)
        # è®¡ç®— step å¥–åŠ±ï¼ˆæ¥å—æ—¶ï¼‰
        progress_delta = 1.0 / max(1, self._progress_total_modules)

        # ==== step(): ç¡¬è¿è§„ ====
        # è¿™äº›æ˜¯ä½  already è®¡ç®—å¥½çš„â€œå½’ä¸€åŒ–â€ costsï¼ˆå»ºè®®å¼±è£å‰ªåˆ° [0, 3~5] èŒƒå›´ï¼‰
        lat = float(np.clip(step_costs.get("latency", 0.0), 0.0, 1.0))
        bw = float(np.clip(step_costs.get("bandwidth", 0.0), 0.0, 1.0))
        commE = float(np.clip(step_costs.get("comm_energy", 0.0), 0.0, 1.0))
        execE = float(np.clip(step_costs.get("exec_energy", 0.0), 0.0, 1.0))

        self.ep_cost_max["latency"] = max(self.ep_cost_max["latency"], lat)
        self.ep_cost_max["bandwidth"] = max(self.ep_cost_max["bandwidth"], bw)
        self.ep_cost_sum["latency"] += lat  # å¯é€‰
        self.ep_cost_sum["bandwidth"] += bw  # å¯é€‰
        self.ep_cost_cnt += 1  # å¯é€‰

        energy = commE + execE
        C_PROGRESS = 1.0
        W_E = 0.5  # èƒ½è€—è¾ƒâ€œè´µâ€
        W_LAT = 5
        W_BW = 1
        TOL = 0.05  # ç»™ 5% çš„å®¹å¿åŒºï¼›è¦æ›´ä¸¥æ ¼å°±è®¾ 0.0

        if getattr(self, "reward_mode", "") == "penalty":
            lat_over = max(0.0, lat - TOL)
            bw_over = max(0.0, bw - TOL)
            reward = (
                    progress_delta
                    - W_LAT * lat_over
                    - W_BW * bw_over
                    - W_E * energy
                    - self.STEP_TIME_COST)

            info = {
                "costs": step_costs, "accepted": True, "rejected": False,
                "rew_terms": {"lat_over": float(lat_over),
                              "bw_over": float(bw_over),
                              "energy": float(W_COMM_ENERGY * commE + W_EXEC_ENERGY * execE),
                              "net": float(reward)},
                "mask_stats": self._mask_stats()
            }
        else:
            # å…³é”®ï¼šæ•´å—ä¹˜ progress_deltaï¼Œä½¿å¾—ä¸€æ¡å®Œæ•´é“¾è·¯ç´¯è®¡å¥–åŠ± ~ O(1)
            reward = progress_delta * (
                    C_PROGRESS  # æ­£å‘æ¨è¿›åŸºçº¿ï¼ˆå¦‚ 1.0ï¼‰
                    - W_E * energy  # å‡èƒ½è€—
                    - W_LAT * lat  # å»¶è¿Ÿ shaping
                    - W_BW * bw  # å¸¦å®½ shaping
            ) - self.STEP_TIME_COST

            info = {
                "costs": step_costs, "accepted": True, "rejected": False,
                "rew_terms": {
                    "progress": float(R_PROGRESS * progress_delta),
                    "energy": float(W_COMM_ENERGY * commE + W_EXEC_ENERGY * execE),
                    "net": float(reward),
                },
                "mask_stats": self._mask_stats()
            }

        if terminated or truncated:
            return self._finalize_all_tasks()

        # ä¸ºä¸‹ä¸€æ­¥æŒ‘é€‰ active ä»»åŠ¡ï¼ˆæœ¬æ­¥å·²æ”¾ç½®å®Œä¸€ä¸ªæ¨¡å—ï¼‰
        self._pick_next_task()
        return obs, float(reward), False, False, info

    def check_all_modules_deployed(self):
        """
        åˆ¤æ–­å½“å‰ episode æ˜¯å¦å·²æŠŠæ‰€æœ‰ä»»åŠ¡çš„æ‰€æœ‰æ¨¡å—éƒ¨ç½²å®Œæˆã€‚
        è¿”å›:
          all_done: bool
          detail: {
            tid: {
              "total_planned": int,   # è®¡åˆ’ä¸­çš„æ¨¡å—æ€»æ•°
              "deployed": int,        # å·²éƒ¨ç½²æ•°
              "remaining": int,       # æœªéƒ¨ç½²æ•°
              "percent": float,       # å®Œæˆæ¯”ä¾‹ 0~1
              "missing_module_ids": [int, ...],  # æœªéƒ¨ç½²çš„ module_id åˆ—è¡¨
              "missing_agents": [int, ...],      # æœªéƒ¨ç½²æ¨¡å—å¯¹åº”çš„ agent_id åˆ—è¡¨ï¼ˆå¦‚å¯è·å–ï¼‰
            }, ...
          }
        """
        detail = {}
        all_done = True

        # ä¾¿åˆ©æ‰€æœ‰ä»»åŠ¡
        task_ids = [int(getattr(tg, "id", -1)) for tg in self.task_graphs]
        for tid in task_ids:
            cur_list = self.current_modules_by_task.get(tid, [])
            q_list = self.modules_queue_by_task.get(tid, [])

            deployed_ids = {int(m.get("module_id", -1)) for m in cur_list}
            planned_ids = deployed_ids | {int(m.get("module_id", -1)) for m in q_list}
            remaining_ids = sorted(list(planned_ids - deployed_ids))

            # å°è¯•ç»™å‡ºæœªéƒ¨ç½²æ¨¡å—å¯¹åº”çš„ agent_idï¼ˆä»å½“å‰é˜Ÿåˆ—/å·²éƒ¨ç½²é‡Œéƒ½æœä¸€éåšæ˜ å°„ï¼‰
            mod2agent = {}
            for m in cur_list:
                mod2agent[int(m.get("module_id", -1))] = int(m.get("agent_id", -1))
            for m in q_list:
                mod2agent[int(m.get("module_id", -1))] = int(m.get("agent_id", -1))
            missing_agents = [mod2agent.get(mid, -1) for mid in remaining_ids]

            total_planned = len(planned_ids)
            deployed_cnt = len(deployed_ids)
            remaining_cnt = total_planned - deployed_cnt
            done_this_task = (remaining_cnt == 0)

            detail[tid] = {
                "total_planned": total_planned,
                "deployed": deployed_cnt,
                "remaining": remaining_cnt,
                "percent": (deployed_cnt / total_planned) if total_planned > 0 else 1.0,
                "missing_module_ids": remaining_ids,
                "missing_agents": missing_agents,
            }
            all_done = all_done and done_this_task

        return all_done, detail

    def _device_for_node_in(self, tid: int, node_id: str, current_module: Dict[str, Any]) -> Optional[int]:
        tg_mods = self.current_modules_by_task.get(tid, [])
        G = next(t for t in self.task_graphs if int(getattr(t, "id", -1)) == tid).G
        node_info = G.nodes[node_id]
        ntype = node_info.get("type", "proc")
        cap_idx = node_info.get("idx")

        if node_id in current_module["nodes"]:
            if ntype == "proc":
                return current_module["soft_device"]
            elif ntype == "sense":
                return current_module["sense_map"].get(cap_idx)
            elif ntype == "act":
                return current_module["act_map"].get(cap_idx)

        for mod in tg_mods:
            if node_id in mod["nodes"]:
                if ntype == "proc":
                    return mod["soft_device"]
                elif ntype == "sense":
                    return mod["sense_map"].get(cap_idx)
                elif ntype == "act":
                    return mod["act_map"].get(cap_idx)
        return None

    def _tri_part_step_reward_for_task(
            self, tid: int, tg: TaskGraph, m: Dict[str, Any], illegal_caps: int
    ) -> tuple[float, dict[str, float], dict[str, Any]]:
        """
        é’ˆå¯¹â€œå½“å‰ä»»åŠ¡ tid çš„å½“å‰æ¨¡å— mâ€çš„ä¸€æ­¥å¥–åŠ±ä¸çº¦æŸåº¦é‡ã€‚
        - ä»…ç»Ÿè®¡ï¼šå½“å‰æ¨¡å— â†” å·²æ”¾ç½®(åŒä¸€ä»»åŠ¡) çš„è·¨æ¨¡å—é“¾è·¯ï¼ˆé¿å…è·¨ä»»åŠ¡ä¸²æ‰°ï¼‰
        - èƒ½åŠ›/èµ„æºå¯è¡Œæ€§æ£€æŸ¥å¤±è´¥ç›´æ¥è¿”å›è´Ÿå¥–åŠ± + å¯¹åº” costs
        - æ–°å¢ï¼šå»¶è¿Ÿ/å¸¦å®½çš„è½»é‡ shapingï¼ˆé¿å…è®­ç»ƒæ—©æœŸå®Œå…¨æ— ä¿¡å·ï¼‰
        """
        # ===== è½»é‡ shaping æƒé‡ï¼ˆä¸ä¸ cSAC çš„ Î» å†²çªï¼‰ =====

        ILLEGAL_ACTION_PENALTY = 2.0  # å•æ­¥çš„è½»è´Ÿå¥–åŠ±ï¼ˆä¿æŒå’Œä½ åŸæ¥ä¸€è‡´çš„é‡çº§ï¼‰

        # ===== ç»Ÿä¸€ä»£ä»·å®¹å™¨ =====
        costs: Dict[str, float] = {
            "illegal_caps": 0.0, "cap_violation": 0.0, "resource_violation": 0.0,
            "latency": 0.0, "bandwidth": 0.0, "comm_energy": 0.0, "exec_energy": 0.0,
            "cap_penalty": 0.0, "resource_penalty": 0.0,
        }
        details: Dict[str, Any] = {}

        # ===== 0) éæ³•èƒ½åŠ›ï¼ˆæ©ç æ— å¯è¡Œè®¾å¤‡å¯¼è‡´çš„â€œå ä½åŠ¨ä½œâ€ï¼‰ =====
        if illegal_caps > 0:
            costs["illegal_caps"] = float(illegal_caps)
            details["illegal"] = {
                "module_id": int(m.get("module_id", -1)),
                "soft_device": int(m.get("soft_device", -1)),
                "count": int(illegal_caps),
            }
            self._log_violation(tid, "illegal", {**details["illegal"]})
            return 0, costs, details

        # ===== 1) èƒ½åŠ›å¯è¡Œæ€§ï¼ˆsoft / sense / actï¼‰ =====
        dev = self.device_map[m["soft_device"]]
        agent = self.agent_lookup[m["agent_id"]]
        req_soft = agent.C_soft

        miss_soft = len(req_soft - dev.soft_cap)
        miss_sense = sum(1 for cap, dv in m["sense_map"].items()
                         if cap not in self.device_map[dv].sense_cap)
        miss_act = sum(1 for cap, dv in m["act_map"].items()
                       if cap not in self.device_map[dv].act_cap)

        if (miss_soft + miss_sense + miss_act) > 0:
            total_miss = miss_soft + miss_sense + miss_act
            penalty_val = float(UNSOLVABLE_MISMATCH_PENALTY * total_miss)
            costs["cap_violation"] = float(total_miss)
            costs["cap_penalty"] = penalty_val
            details["cap"] = {
                "module_id": int(m.get("module_id", -1)),
                "soft_device": int(m.get("soft_device", -1)),
                "missing_soft": int(miss_soft),
                "missing_act": int(miss_act),
                "missing_sense": int(miss_sense),
            }
            self._log_violation(tid, "cap", {**details["cap"]})
            return 0, costs, details

        # ===== 2) èµ„æºå¯è¡Œæ€§ï¼ˆå››ç»´ num/gpu_mem/ram/diskï¼‰ =====
        need6 = np.array(self.agent_lookup[m["agent_id"]].r, dtype=np.float32)
        need4 = need6[[1, 3, 4, 5]]
        used4 = self.resource_used[m["soft_device"]][[1, 3, 4, 5]]
        cap4 = self._cap4(self.device_map[m["soft_device"]])
        if np.any(used4 + need4 > cap4 + 1e-6):
            costs["resource_violation"] = 1.0
            penalty_val = float(W_RES_VIOLATION * 2.0)
            costs["resource_penalty"] = penalty_val

            names = ["num", "gpu_mem", "ram", "disk"]
            over = (used4 + need4) - cap4
            detail_list = []
            for i, n in enumerate(names):
                if over[i] > 1e-6:
                    detail_list.append({
                        "resource": n,
                        "used": float(used4[i]),
                        "need": float(need4[i]),
                        "cap": float(cap4[i]),
                        "excess": float(over[i]),
                    })
            self._log_violation(tid, "resource", {
                "module_id": int(m.get("module_id", -1)),
                "soft_device": int(m.get("soft_device", -1)),
                "details": detail_list,
            })
            return 0.0, costs, {"resource": {"details": detail_list}}

        # ===== 3) é€šä¿¡è¿çº¦ä¸é€šä¿¡èƒ½è€—ï¼ˆä»…ç»Ÿè®¡ï¼šå½“å‰æ¨¡å— â†” å·²æ”¾ç½®(åŒä»»åŠ¡)ï¼‰ =====
        G = tg.G
        lat_violations: List[float] = []
        bw_violations: List[float] = []
        comm_energy = 0.0

        # ç¼ºçœå‚æ•°
        SENSE_DATA_MB_DEFAULT, CTRL_DATA_MB_DEFAULT, PROC_DATA_MB_DEFAULT = 0.5, 0.1, 1.0
        LAT_REQ_DEFAULT, BW_REQ_DEFAULT = 50.0, 0.0

        # ä»…çœ‹â€œå½“å‰ä»»åŠ¡â€çš„å·²æ”¾ç½®èŠ‚ç‚¹é›†åˆ
        assigned = self.assigned_nodes_by_task.get(tid, set())

        def _edge_defaults(u_type, v_type, attr):
            data_mb = attr.get("data_size")
            bw_req = attr.get("bandwidth_req")
            lat_req = attr.get("latency_req")
            if data_mb is None:
                if u_type == "sense" and v_type == "proc":
                    data_mb = SENSE_DATA_MB_DEFAULT
                elif u_type == "proc" and v_type == "act":
                    data_mb = CTRL_DATA_MB_DEFAULT
                else:
                    data_mb = PROC_DATA_MB_DEFAULT
            if bw_req is None:
                bw_req = BW_REQ_DEFAULT
            if lat_req is None:
                lat_req = 20.0 if ((u_type == "sense" and v_type == "proc") or
                                   (u_type == "proc" and v_type == "act")) else LAT_REQ_DEFAULT
            return data_mb, bw_req, lat_req

        for u, v, attr in tg.get_dependencies():
            u_in_cur = (u in m["nodes"])
            v_in_cur = (v in m["nodes"])

            u_type = G.nodes[u].get("type", "proc")
            v_type = G.nodes[v].get("type", "proc")

            # A) æ¨¡å—å†…é“¾è·¯ï¼šu,v éƒ½åœ¨å½“å‰æ¨¡å—
            if u_in_cur and v_in_cur:
                du = self._device_for_node_in(tid, u, m)
                dv = self._device_for_node_in(tid, v, m)
                if du is None or dv is None or du == dv:
                    continue
                data_mb, bw_req, lat_req = _edge_defaults(u_type, v_type, attr)
                dms, bw_act, ej = compute_transmission_delay(
                    src=self.device_map[du], dst=self.device_map[dv],
                    data_size_mb=data_mb, bw_req=bw_req, gw_matrix=self.gw_matrix
                )
                lat_violations.append(norm_latency(dms, lat_req))
                bw_violations.append(norm_bandwidth(bw_act, bw_req))
                comm_energy += float(ej)
                continue
            # B) è·¨æ¨¡å—é“¾è·¯ï¼šu,v å…¶ä¸­ä¹‹ä¸€åœ¨å½“å‰æ¨¡å—ï¼›å¦ä¸€ç«¯å¿…é¡»å·²æ”¾ç½®ï¼ˆåŒä»»åŠ¡ï¼‰
            if u_in_cur != v_in_cur:
                other = v if u_in_cur else u
                if other not in assigned:
                    continue  # å¦ä¸€ç«¯è¿˜æ²¡æ”¾ï¼Œä¸åœ¨æœ¬æ­¥ç»Ÿè®¡
                du = self._device_for_node_in(tid, u, m)  # å½“å‰ç«¯ç‚¹ç”¨ mï¼›å·²æ”¾ç½®ç«¯ç‚¹ä»å†å²æ¨¡ç»„é‡ŒæŸ¥
                dv = self._device_for_node_in(tid, v, m)
                if du is None or dv is None or du == dv:
                    continue
                data_mb, bw_req, lat_req = _edge_defaults(u_type, v_type, attr)
                dms, bw_act, ej = compute_transmission_delay(
                    src=self.device_map[du], dst=self.device_map[dv],
                    data_size_mb=data_mb, bw_req=bw_req, gw_matrix=self.gw_matrix
                )
                lat_violations.append(norm_latency(dms, lat_req))
                bw_violations.append(norm_bandwidth(bw_act, bw_req))
                comm_energy += float(ej)
                continue

        # âœ… åªæ›´æ–°â€œå½“å‰ä»»åŠ¡â€çš„å·²æ”¾ç½®é›†åˆ
        self.assigned_nodes_by_task.setdefault(tid, set()).update(m["nodes"])

        costs["latency"] = float(max(lat_violations) if lat_violations else 0.0)
        costs["bandwidth"] = float(max(bw_violations) if bw_violations else 0.0)

        # ===== 4) è®¡ç®—æ‰§è¡Œèƒ½è€— + å³æ—¶å¥–åŠ±ï¼ˆå« shapingï¼‰ =====
        need = np.array(self.agent_lookup[m["agent_id"]].r, dtype=np.float32)
        cpu_cap = float(getattr(dev.resource, "cpu", 0.0))
        gpu_cap = float(getattr(dev.resource, "gpu", 0.0))
        cpu_pow = float(getattr(dev.resource, "cpu_power", 0.0))
        gpu_pow = float(getattr(dev.resource, "gpu_power", 0.0))

        cpu_time = need[0] / cpu_cap if cpu_cap > 0 else 0.0
        gpu_time = need[2] / gpu_cap if gpu_cap > 0 else 0.0
        E_cpu = (cpu_time * cpu_pow) / 3600.0 if cpu_pow > 0 else 0.0
        E_gpu = (gpu_time * gpu_pow) / 3600.0 if gpu_pow > 0 else 0.0
        exec_energy = float(E_cpu + E_gpu)

        # å½’ä¸€åŒ–èƒ½è€—ï¼ˆä¸ç¯å¢ƒåˆå§‹åŒ–æ—¶çš„åˆ†æ¯ä¸€è‡´ï¼‰
        comm_e = float(np.clip(comm_energy / self.comm_energy_norm, 0.0, 1.0))
        exec_e = float(np.clip(exec_energy / self.exec_energy_norm, 0.0, 1.0))
        costs["comm_energy"] = comm_e
        costs["exec_energy"] = exec_e

        # å³æ—¶å¥–åŠ±ï¼šè¿›åº¦ - èƒ½è€— - è½»é‡(å»¶è¿Ÿ/å¸¦å®½) shaping
        # reward = (
        #         R_PROGRESS
        #         - (W_COMM_ENERGY * comm_e + W_EXEC_ENERGY * exec_e)
        #         - (W_LAT_SHAPING * costs["latency"])
        #         - (W_BW_SHAPING * costs["bandwidth"])
        # )
        return float(0), costs, details

    def _cap4(self, dev):
        vals = []
        dev_type = str(getattr(dev, "type", "")).lower()
        unlimited = (dev_type in ("edge", "cloud"))
        for name in ("num", "gpu_mem", "ram", "disk"):
            v = getattr(dev.resource, name, None)
            if v is None:
                v = 0.0
            if (v == 0 or v is None) and unlimited:
                v = 1e9  # è§†ä¸ºå‡ ä¹ä¸å—é™
            vals.append(float(v))
        return np.array(vals, dtype=np.float32)


def create_tripart_env(seed=42, K_s_max=6, K_a_max=6,
                       max_module_size=8, min_module_size=1,
                       lns_rounds=300, grasp_runs=40, grasp_rcl_k=3,
                       precomputed_plans_path: Optional[str] = "plans.json"
                       ):
    cloud, device_list, edge_list, gw_matrix = load_infrastructure()

    device_num = len(device_list)
    edge_num = len(edge_list)
    # ç»™ Edge æœåŠ¡å™¨åˆ†é…è¿ç»­ id
    for idx, edge in enumerate(edge_list, start=device_num + 1):
        edge.id = idx  # ä¾‹å¦‚ IoT æœ‰ 25 å°ï¼Œåˆ™ç¬¬ä¸€å° Edge ä» 26 å¼€å§‹

    device_map = {d.id: d for d in device_list}
    device_map.update({e.id: e for e in edge_list})
    # Cloud æœåŠ¡å™¨ id
    cloud.id = device_num + edge_num + 1  # å”¯ä¸€ç¼–å·

    device_map[cloud.id] = cloud

    df = pd.read_csv("redundant_agent_templates.csv")
    agent_lookup = build_agent_lookup(df)

    task_graphs = []
    for i in range(1, 11):
        tg = TaskGraph()
        with open(f"task/dag{i}_typed_constraint.json", "r") as f:
            data = json.load(f)
            tg.load_from_json(data, i)
            task_graphs.append(tg)

    env = TriPartPlacementEnv(
        task_graphs, agent_lookup, device_map, gw_matrix,
        K_s_max=K_s_max, K_a_max=K_a_max, seed=seed,
        # NEW â†“â†“â†“
        max_module_size=max_module_size,
        min_module_size=min_module_size,
        lns_rounds=lns_rounds,
        grasp_runs=grasp_runs,
        grasp_rcl_k=grasp_rcl_k,
        grasp_weights=GRASP_DEFAULT_WEIGHTS,
        # å…³é”®ï¼šè¯»å–é¢„è®¡ç®—æ–¹æ¡ˆ
        precomputed_plans=None,
        precomputed_plans_path=precomputed_plans_path,
        strict_fingerprint_check=True,
    )
    return DummyVecEnv([lambda: Monitor(env)])


def train_tripart_csac(total_steps=200_000, seed=42, K_s_max=6, K_a_max=6,
                       precomputed_plans_path: Optional[str] = "plans.json"):
    env = create_tripart_env(
        seed=seed, K_s_max=K_s_max, K_a_max=K_a_max,
        max_module_size=5, min_module_size=1,
        lns_rounds=300, grasp_runs=40, grasp_rcl_k=3,
        precomputed_plans_path=precomputed_plans_path
    )
    base_env = env.envs[0]  # Monitor åŒ…äº†ä¸€å±‚
    obs, _ = base_env.reset(seed=seed)
    # é€šè¿‡åŠ¨ä½œç©ºé—´è·å–æ¯å¤´å¯é€‰è®¾å¤‡æ•°ï¼ˆMonitor åŒ…è£…ååŒæ ·å¯ç”¨ï¼‰
    nvec = base_env.action_space.nvec
    num_devices = int(nvec[1])  # ç¬¬ 1 ç»´æ‰æ˜¯è®¡ç®—è®¾å¤‡å¤´

    cfg = CSACConfig(
        buffer_size=200_000,
        batch_size=256,
        gamma=0.99, tau=0.005, lr=3e-4,
        alpha_init=0.2, target_entropy_per_head=-np.log(max(1, num_devices)),
        lambda_lr=5e-3,
        constraint_keys=["latency", "bandwidth", "resource_violation", "illegal_caps", "cap_violation"],
        cost_limits={"latency": 5e-2, "bandwidth": 5e-2, "resource_violation": 0, "illegal_caps": 0,
                     "cap_violation": 0}, warmup_steps=10_000, updates_per_step=1,
        device="cuda" if torch.cuda.is_available() else "cpu",
    )
    algo = ConstrainedDiscreteSAC(base_env, cfg)

    rng = np.random.default_rng(seed)
    ep_ret, ep_len = 0.0, 0
    episode_idx = 1
    # === NEW: æ—¥å¿—å™¨ ===
    run_logger = TrainRunLogger(log_dir=LOG_DIR, run_name="cSAC")
    try:
        for t in range(1, total_steps + 1):
            # åŠ¨ä½œ
            obs_t = _to_torch_obs(obs, algo.device)
            action, _ = algo.policy.act(obs_t, deterministic=False)

            next_obs, reward, done, trunc, info = base_env.step(action[0])  # action shape (1,H) -> å–[0]
            costs = info.get("costs", {})
            # === NEW: é€æ­¥æ—¥å¿—ï¼ˆå« step ä¸ episodeï¼‰===
            run_logger.log_step(step=t, episode=episode_idx, reward=float(reward), costs=costs, info=info)

            costs = info.get("costs", {})  # env å·²åœ¨ step ä¸­æ”¾è¿›å»
            # åœ¨è®­ç»ƒ loop é‡Œï¼š
            # if costs.get("illegal_caps", 0) > 0:
            # # print("[DEBUG][illegal]", costs.get("illegal_detail"))
            for rec in info.get("violation_log", []):
                if rec and float(rec.get("penalty", 0)) > 0:
                    print(
                        f"[step={rec.get('step')}] task={rec.get('task_id')} type={rec.get('type')} penalty={rec.get('penalty')}")

            algo.replay.add(obs, action[0], float(reward), next_obs, bool(done or trunc), costs)

            obs = next_obs
            ep_ret += float(reward)
            ep_len += 1

            if done or trunc:
                # ç»ˆå±€ä¿¡æ¯
                print(f"[cSAC] Ep {episode_idx} done: ret={ep_ret:.2f}, len={ep_len}, status={info.get('status')}, "
                      f"obj={0.5 * info.get('makespan', -1) + 0.5 * info.get('energy', -1):.2f},mk={info.get('makespan', -1):.2f}, en={info.get('energy', -1):.2f}, pen={info.get('penalty', -1):.2f}")
                # === NEW: å›åˆæ—¥å¿— ===
                run_logger.log_episode(
                    episode=episode_idx,
                    ep_return=ep_ret,
                    ep_len=ep_len,
                    final_info=info
                )
                episode_idx += 1
                obs, _ = base_env.reset(seed=int(rng.integers(0, 10_000)))
                ep_ret, ep_len = 0.0, 0

            # æ›´æ–°
            if len(algo.replay) > cfg.warmup_steps:
                for _ in range(cfg.updates_per_step):
                    batch = algo.replay.sample(cfg.batch_size)
                    log_info = algo.update(batch)
                    if t % 2000 == 0:
                        print(f"[cSAC] t={t} | "
                              f"Q={log_info['critic_loss']:.3f} | Pi={log_info['policy_loss']:.3f} | "
                              f"alpha={log_info['alpha']:.3f} | "
                              f"Î»_lat={log_info.get('lambda_latency', 0):.3f}({log_info.get('avg_latency', 0):.3f}) | "
                              f"Î»_bw={log_info.get('lambda_bandwidth', 0):.3f}({log_info.get('avg_bandwidth', 0):.3f})")
    finally:
        # === NEW: è®­ç»ƒç»“æŸç¡®ä¿è½ç›˜ ===
        run_logger.close()
        paths = run_logger.paths
        print(f"[cSAC] Training logs saved:\n  - steps:    {paths['steps']}\n  - episodes: {paths['episodes']}")
    return algo


def evaluate_tripart_csac(algo,
                          episodes: int = 10,
                          seed: int = 123,
                          deterministic: bool = True):
    """
    ä½¿ç”¨ cSAC çš„ç­–ç•¥è¿›è¡Œçº¯è¯„ä¼°ï¼ˆä¸å­¦ä¹ ï¼‰ã€‚
    - algo: ConstrainedDiscreteSAC å®ä¾‹ï¼ˆå†…å« env ä¸ policyï¼‰
    - episodes: è¯„ä¼°å›åˆæ•°
    - deterministic: æ˜¯å¦ç”¨è´ªå¿ƒåŠ¨ä½œï¼ˆTrue=argmaxï¼‰
    """
    # å…¼å®¹ DummyVecEnv(Monitor(...)) æˆ–åŸç”Ÿ env
    env = getattr(algo, "env", None)
    if env is None:
        raise ValueError("algo.env is None. Please pass the cSAC algo created by train_tripart_csac.")
    base_env = env.envs[0] if hasattr(env, "envs") else env

    rng = np.random.default_rng(seed)

    ep_summaries = []
    cost_keys = ["latency", "bandwidth", "comm_energy", "exec_energy"]

    for ep in range(episodes):
        obs, _ = base_env.reset(seed=int(seed + ep))
        done, trunc = False, False
        ep_ret, ep_len = 0.0, 0

        # ç´¯è®¡çº¦æŸæˆæœ¬ï¼ˆæŒ‰å›åˆæ±‚å‡å€¼ï¼‰
        cost_acc = {k: 0.0 for k in cost_keys}
        cost_cnt = 0

        final_info = {}

        while not (done or trunc):
            # ç”¨ cSAC ç­–ç•¥å‡ºåŠ¨ä½œ
            a, _ = algo.policy.act(_to_torch_obs(obs, algo.device), deterministic=deterministic)
            # act è¿”å› (1,H)ï¼Œéœ€è¦å–ç¬¬ 0 ä¸ªæ ·æœ¬
            obs, r, done, trunc, info = base_env.step(a[0])

            ep_ret += float(r)
            ep_len += 1
            final_info = info

            # è®°å½• step çš„ costs
            step_costs = info.get("costs", {})
            for k in cost_keys:
                cost_acc[k] += float(step_costs.get(k, 0.0))
            cost_cnt += 1

        # å›åˆçº§ç»Ÿè®¡
        avg_costs = {k: (cost_acc[k] / max(1, cost_cnt)) for k in cost_keys}
        summary = {
            "episode": ep + 1,
            "reward": ep_ret,
            "length": ep_len,
            "status": final_info.get("status", "unknown"),
            "makespan": float(final_info.get("makespan", -1.0)),
            "energy": float(final_info.get("energy", -1.0)),
            "penalty": float(final_info.get("penalty", -1.0)),
            **{f"avg_{k}": v for k, v in avg_costs.items()}
        }
        ep_summaries.append(summary)

        print(
            f"[cSAC Eval] Ep {ep + 1:02d} | "
            f"Ret={summary['reward']:.2f} Len={summary['length']:3d} | "
            f"Status={summary['status']} | "
            f"mk={summary['makespan']:.2f} en={summary['energy']:.2f} pen={summary['penalty']:.2f} | "
            f"lat={summary['avg_latency']:.3f} bw={summary['avg_bandwidth']:.3f} "
            f"ce={summary['avg_comm_energy']:.3f} ee={summary['avg_exec_energy']:.3f}"
        )

    # æ•´ä½“æ±‡æ€»
    import numpy as _np

    def _safe_avg(arr):
        return float(_np.mean(arr)) if len(arr) > 0 else float("nan")

    rets = [x["reward"] for x in ep_summaries]
    lens = [x["length"] for x in ep_summaries]
    succ = [x for x in ep_summaries if x["status"] == "success"]
    succ_rate = len(succ) / max(1, episodes)

    agg = {
        "episodes": episodes,
        "avg_reward": _safe_avg(rets),
        "avg_length": _safe_avg(lens),
        "success_rate": succ_rate,
        "success_avg_makespan": _safe_avg([x["makespan"] for x in succ]),
        "success_avg_energy": _safe_avg([x["energy"] for x in succ]),
        "success_avg_penalty": _safe_avg([x["penalty"] for x in succ]),
        "all_avg_latency": _safe_avg([x["avg_latency"] for x in ep_summaries]),
        "all_avg_bandwidth": _safe_avg([x["avg_bandwidth"] for x in ep_summaries]),
        "all_avg_comm_energy": _safe_avg([x["avg_comm_energy"] for x in ep_summaries]),
        "all_avg_exec_energy": _safe_avg([x["avg_exec_energy"] for x in ep_summaries]),
    }

    print("\n[cSAC Eval] ===== Summary =====")
    print(
        f"Episodes={agg['episodes']} | "
        f"AvgRet={agg['avg_reward']:.2f} | AvgLen={agg['avg_length']:.1f} | "
        f"SuccRate={agg['success_rate'] * 100:.1f}%"
    )
    print(
        f"Success Only -> "
        f"AvgMakespan={agg['success_avg_makespan']:.3f} | "
        f"AvgEnergy={agg['success_avg_energy']:.3f} | "
        f"AvgPenalty={agg['success_avg_penalty']:.3f}"
    )
    print(
        f"All Episodes Avg Costs -> "
        f"Latency={agg['all_avg_latency']:.3f} | "
        f"Bandwidth={agg['all_avg_bandwidth']:.3f} | "
        f"CommE={agg['all_avg_comm_energy']:.3f} | "
        f"ExecE={agg['all_avg_exec_energy']:.3f}"
    )
    return {"episodes": ep_summaries, "summary": agg}


# <<< NEW: Custom Callback for logging training data >>>
class TrainingLoggerCallback(BaseCallback):
    def __init__(self, log_path: str, level_name: str, verbose: int = 0):
        super().__init__(verbose)
        self.log_path = log_path
        self.level_name = level_name
        self.episode_data = []
        self.start_time = time.time()

    def _on_step(self) -> bool:
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¯å¢ƒå®Œæˆäº† Episode
        # æˆ‘ä»¬ä»æ—¥å¿—ä¸­å·²ç»ç¡®è®¤ï¼Œè¿™ä¸ªæ¡ä»¶æ˜¯ä¼šæ»¡è¶³çš„
        if self.locals["dones"][0]:
            info = self.locals["infos"][0]

            # <<< æ ¸å¿ƒä¿®å¤ï¼šç›´æ¥ä» info å­—å…¸é¡¶å±‚è·å–æ•°æ® >>>
            # æˆ‘ä»¬ä¸å†æŸ¥æ‰¾ 'episode' æˆ– 'final_info'ï¼Œå› ä¸ºæ—¥å¿—æ˜¾ç¤ºå®ƒä»¬ä¸å­˜åœ¨ã€‚

            # å°è¯•è·å– SB3 çš„ 'episode' é”®ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤å€¼
            # æ³¨æ„ï¼šåœ¨ä½ çš„æ—¥å¿—ä¸­ï¼Œè¿™ä¸ªé”®ä¸å­˜åœ¨ï¼Œæ‰€ä»¥ä¼šä½¿ç”¨é»˜è®¤å€¼
            ep_info = info.get("episode")
            ep_reward = ep_info["r"] if ep_info else -999.0  # ä½¿ç”¨ä¸€ä¸ªæ˜æ˜¾çš„å€¼è¡¨ç¤ºæ•°æ®ç¼ºå¤±
            ep_length = ep_info["l"] if ep_info else -1

            # ç›´æ¥ä» info å­—å…¸è·å–æˆ‘ä»¬çš„è‡ªå®šä¹‰æ€§èƒ½æŒ‡æ ‡
            makespan = info.get("makespan", -1.0)
            energy = info.get("energy", -1.0)
            # æ³¨æ„ï¼špenalty æ˜¯ np.float64 ç±»å‹ï¼Œéœ€è¦è½¬æ¢ä¸º float ä»¥ä¾¿æ ¼å¼åŒ–
            penalty = float(info.get("penalty", -1.0))
            status = info.get("status", "unknown")

            # è®°å½•æ•°æ®
            self.episode_data.append({
                "timesteps": self.num_timesteps,
                "episode_reward": ep_reward,
                "episode_length": ep_length,
                "makespan": makespan,
                "energy": energy,
                "penalty": penalty,
                "status": status
            })

            # è®¡ç®—å¹¶æ‰“å°æ—¥å¿—
            now = time.time()
            duration = now - self.start_time
            sps = self.num_timesteps / duration if duration > 0 else 0

            log_str = (
                f"[{self.level_name}] "
                f"TS: {self.num_timesteps:<8} | "
                f"Ep: {len(self.episode_data):<5} | "
                f"Reward: {ep_reward:<8.2f} | "  # Reward ä¼šæ˜¾ç¤º -999.00
                f"Len: {ep_length:<4} | "
                f"Status: {status:<22} | "
                f"Makespan: {makespan:<7.2f} | "
                f"Energy: {energy:<8.2f} | "
                f"Penalty: {penalty:<6.2f} | "
                f"SPS: {int(sps):<5}"
            )
            print(log_str)

        return True

    def _on_training_end(self) -> None:
        if self.episode_data:
            df = pd.DataFrame(self.episode_data)
            df.to_csv(self.log_path, index=False)
            if self.verbose > 0:
                print(f"[{self.level_name}] Training log with {len(df)} episodes saved to {self.log_path}")


# === NEW: Simple run logger for manual cSAC training ===
import os, csv
from datetime import datetime


class TrainRunLogger:
    """
    è®°å½•ä¸¤ç±»æ—¥å¿—ï¼š
    - steps.csvï¼šæ¯ä¸ªç¯å¢ƒæ­¥çš„ä¿¡æ¯ï¼ˆstep, episode, reward, costs...ï¼‰
    - episodes.csvï¼šæ¯ä¸ªå›åˆçš„èšåˆæŒ‡æ ‡ï¼ˆepisode, ret, len, makespan, energy, penalty, status...ï¼‰
    """

    def __init__(self, log_dir: str = "logs", run_name: str | None = None):
        os.makedirs(log_dir, exist_ok=True)
        stamp = run_name or datetime.now().strftime("%Y%m%d-%H%M%S")
        self.step_path = os.path.join(log_dir, f"steps_{stamp}.csv")
        self.ep_path = os.path.join(log_dir, f"episodes_{stamp}.csv")

        # å†™å…¥ CSV å¤´
        self._step_writer = None
        self._ep_writer = None
        self._step_f = open(self.step_path, "w", newline="", encoding="utf-8")
        self._ep_f = open(self.ep_path, "w", newline="", encoding="utf-8")

    def log_step(self, *, step: int, episode: int, reward: float, costs: dict, info: dict):
        # ç»Ÿä¸€ä¸€äº›å¸¸è§é”®ï¼Œç¼ºå¤±åˆ™ç»™é»˜è®¤å€¼
        row = {
            "step": step,
            "episode": episode,
            "reward": float(reward),
            "latency": float(costs.get("latency", 0.0)),
            "bandwidth": float(costs.get("bandwidth", 0.0)),
            "comm_energy": float(costs.get("comm_energy", 0.0)),
            "exec_energy": float(costs.get("exec_energy", 0.0)),
            "illegal_caps": float(costs.get("illegal_caps", 0.0)),
            "cap_violation": float(costs.get("cap_violation", 0.0)),
            "resource_violation": float(costs.get("resource_violation", 0.0)),
            "rejected": bool(info.get("rejected", False)),
        }
        # æ‡’åˆå§‹åŒ– writerï¼ˆæ ¹æ®é¦–æ¬¡è¡Œçš„åˆ—ååˆ›å»ºï¼‰
        if self._step_writer is None:
            self._step_writer = csv.DictWriter(self._step_f, fieldnames=list(row.keys()))
            self._step_writer.writeheader()
        self._step_writer.writerow(row)

    def log_episode(self, *, episode: int, ep_return: float, ep_len: int, final_info: dict):
        row = {
            "episode": episode,
            "episode_return": float(ep_return),
            "episode_length": int(ep_len),
            "status": str(final_info.get("status", "unknown")),
            "makespan": float(final_info.get("makespan", -1.0)),
            "energy": float(final_info.get("energy", -1.0)),
            "penalty": float(final_info.get("penalty", -1.0)),
            "max_latency_cost": float(final_info.get("max_latency_cost", 0.0)),
            "max_bandwidth_cost": float(final_info.get("max_bandwidth_cost", 0.0)),
            "feasible": bool(final_info.get("feasible", False)),
        }
        if self._ep_writer is None:
            self._ep_writer = csv.DictWriter(self._ep_f, fieldnames=list(row.keys()))
            self._ep_writer.writeheader()
        self._ep_writer.writerow(row)

    def close(self):
        try:
            self._step_f.flush();
            self._ep_f.flush()
        finally:
            self._step_f.close();
            self._ep_f.close()

    @property
    def paths(self):
        return {"steps": self.step_path, "episodes": self.ep_path}


# <<< NEW: å‡½æ•°ç”¨äºç”Ÿæˆè¯¦ç»†çš„éƒ¨ç½²æ–¹æ¡ˆæŠ¥å‘Š >>>
def generate_deployment_report(
        placement: Dict[Tuple[int, int], Dict],
        task_graph: TaskGraph,
        agent_lookup: Dict[int, AgentTemplate],
        device_map: Dict[int, Device],
        final_info: Dict
) -> Dict:
    """
    å°†æœ€ç»ˆçš„éƒ¨ç½²æ–¹æ¡ˆï¼ˆplacementï¼‰è½¬æ¢æˆä¸€ä¸ªè¯¦ç»†ã€æ˜“è¯»çš„å­—å…¸/JSONæŠ¥å‘Šã€‚

    Args:
        placement: æœ€ç»ˆçš„éƒ¨ç½²æ–¹æ¡ˆå­—å…¸ã€‚
        task_graph: å¯¹åº”çš„ä»»åŠ¡å›¾ã€‚
        agent_lookup: æ™ºèƒ½ä½“æ¨¡æ¿æŸ¥æ‰¾è¡¨ã€‚
        device_map: è®¾å¤‡å®ä¾‹æŸ¥æ‰¾è¡¨ã€‚
        final_info: åŒ…å«æœ€ç»ˆæ€§èƒ½æŒ‡æ ‡çš„å­—å…¸ã€‚

    Returns:
        ä¸€ä¸ªåŒ…å«å®Œæ•´éƒ¨ç½²ç»†èŠ‚çš„å­—å…¸ã€‚
    """
    task_id = task_graph.task_id if hasattr(task_graph, 'task_id') else list(placement.keys())[0][0]

    report = {
        "task_id": task_id,
        "overall_performance": final_info,
        "deployment_plan": []
    }

    # --- é¢„å¤„ç†ï¼šå»ºç«‹ä¸€ä¸ªå¿«é€ŸæŸ¥æ‰¾è¡¨ï¼Œç”¨äºæŸ¥æ‰¾å“ªä¸ªæ™ºèƒ½ä½“æä¾›å“ªä¸ªä¼ æ„Ÿå™¨èƒ½åŠ› ---
    sensor_provider_map = {}
    for (tid, mod_id), mod_info in placement.items():
        agent = agent_lookup[mod_info["agent_id"]]
        for sensor_cap in agent.C_sense:
            sensor_provider_map[sensor_cap] = {
                "agent_id": agent.id,
                "module_id": mod_id
            }

    # --- éå†æ¯ä¸ªæ¨¡å—ï¼Œç”Ÿæˆå…¶è¯¦ç»†æŠ¥å‘Š ---
    sorted_modules = sorted(placement.items(), key=lambda item: item[0][1])  # æŒ‰ module_id æ’åº

    for (tid, module_id), info in sorted_modules:
        agent = agent_lookup[info["agent_id"]]

        # 1. è·å–æ¨¡å—æ‰€éœ€çš„èƒ½åŠ›
        required_sense, _, _ = get_module_capabilities(task_graph.G, info["nodes"])

        # 2. è¯†åˆ«ç¼ºå¤±å’Œéœ€è¦åä½œçš„ä¼ æ„Ÿå™¨
        missing_sensors = required_sense - agent.C_sense
        collaboration_details = []
        for missing_cap in missing_sensors:
            if missing_cap in sensor_provider_map:
                provider = sensor_provider_map[missing_cap]
                collaboration_details.append({
                    "capability_id": missing_cap,
                    "status": "Collaborative",
                    "provided_by_agent_id": provider["agent_id"],
                    "in_module_id": provider["module_id"]
                })
            else:
                collaboration_details.append({
                    "capability_id": missing_cap,
                    "status": "Missing (Unsolved)",
                    "provided_by_agent_id": None,
                    "in_module_id": None
                })

        # 3. æ•´ç†è®¾å¤‡éƒ¨ç½²ä¿¡æ¯
        soft_dev_id = info["soft_device"]
        device_deployments = {
            "software_deployment": {
                "device_id": soft_dev_id,
                "device_type": device_map[soft_dev_id].type
            },
            "sensor_deployments": [
                {
                    "capability_id": cap_id,
                    "device_id": dev_id,
                    "device_type": device_map[dev_id].type
                } for cap_id, dev_id in info["sense_map"].items()
            ],
            "actuator_deployments": [
                {
                    "capability_id": cap_id,
                    "device_id": dev_id,
                    "device_type": device_map[dev_id].type
                } for cap_id, dev_id in info["act_map"].items()
            ]
        }

        # 4. ç»„è£…è¯¥æ¨¡å—çš„æŠ¥å‘Š
        module_report = {
            "module_id": module_id,
            "nodes": sorted(list(info["nodes"])),  # æ’åºä»¥ä¿è¯è¾“å‡ºä¸€è‡´æ€§
            "assigned_agent_template_id": agent.id,
            "deployment_devices": device_deployments,
            "collaboration_details": {
                "required_sensors": sorted(list(required_sense)),
                "provided_by_this_agent": sorted(list(agent.C_sense)),
                "collaborative_sensors_needed": collaboration_details
            }
        }
        report["deployment_plan"].append(module_report)

    return report


def build_and_save_stage1_plans(
        save_path: str = "plans.json",
        max_module_size: int = 8,
        grasp_weights: Optional[Weights] = None,
        params: Optional[GRASPParams] = None,
        seed: int = 42,
):
    """
    ä¸€æ¬¡æ€§å¯¹æ‰€æœ‰ task_graphs ç”Ÿæˆ Stage-1 æ–¹æ¡ˆå¹¶ä¿å­˜ã€‚
    ä½¿ç”¨ä¸ä½ è®­ç»ƒç›¸åŒçš„ load_infrastructure / build_agent_lookup / TaskGraph åŠ è½½æµç¨‹ã€‚
    """
    cloud, device_list, edge_list, gw_matrix = load_infrastructure()
    device_map = {d.id: d for d in device_list}
    device_map.update({e.id: e for e in edge_list})
    cloud.id = max(device_map.keys()) + 1
    device_map[cloud.id] = cloud

    df = pd.read_csv("redundant_agent_templates.csv")
    agent_lookup = build_agent_lookup(df)

    # åŠ è½½ä»»åŠ¡
    task_graphs = []
    table = []  # NEW: æ±‡æ€»è¡¨
    for i in range(1, 11):
        tg = TaskGraph()
        with open(f"task/dag{i}_typed_constraint.json", "r") as f:
            data = json.load(f)
            tg.load_from_json(data, i)
            task_graphs.append(tg)

    rng = np.random.default_rng(seed)
    plans_by_task: Dict[int, Dict[str, Any]] = {}

    # --- æ‰¹é‡ç”Ÿæˆ plan ---
    all_plans = []
    for tg in task_graphs:
        plan = solve_stage1_partition_and_match(
            tg, agent_lookup,
            max_module_size=max_module_size,
            weights=grasp_weights,
            params=params,
            seed=seed,
            verbose=True,
        )
        ser = serialize_partition_plan(tg.G, plan)
        all_plans.append(ser)
        print(f"[Stage-1] Task {tg.id}: modules={len(plan['modules'])}, "
              f"objective={plan['objective']:.2f}")

    if table:
        print("\n[Stage-1] Summary")
        print(" Task | #Modules | MaxSize | TotalNodes | Objective")
        print("------+----------+---------+------------+----------")
        for tid, k, smax, totaln, obj in table:
            print(f"{tid:5d} | {k:8d} | {smax:7d} | {totaln:10d} | {obj:9.3f}")

    # --- ä¿å­˜ ---
    with open(save_path, "w", encoding="utf-8") as f:
        json.dump(all_plans, f, ensure_ascii=False, indent=2)
    print(f"[Stage-1] Saved {len(all_plans)} plans to {save_path}")


if __name__ == "__main__":
    # ä¾‹ï¼šæƒé‡ï¼ˆä¸æ—§å­—å…¸ç­‰ä»·ï¼›å¯æŒ‰éœ€è°ƒæ•´æˆ–ç½®ä¸º Noneï¼‰
    weights = Weights(
        w_module=0.20,  # æ¨¡å—æ•°æƒé‡
        w_interface=1.00,  # è·¨æ¨¡å—æ¥å£æƒé‡
        w_redund=0.30,  # èƒ½åŠ›å†—ä½™æƒé‡
        w_collab=0.60,  # åä½œæ¬¡æ•°æƒé‡
        w_balance=0.15  # æ¨¡å—è´Ÿè½½å‡è¡¡æƒé‡
    )

    # ä¾‹ï¼šå‚æ•°ï¼ˆå« LNS è½®æ¬¡/ç ´åæ¯”ä¾‹/LS è¿­ä»£ç­‰ï¼›å¯æŒ‰éœ€è°ƒæ•´æˆ–ç½®ä¸º Noneï¼‰
    params = GRASPParams(
        ls_iters=200,
        lns_rounds=300,
        lns_destroy_frac=0.25
    )

    # 1) é¢„ç”Ÿæˆ plansï¼ˆç»Ÿä¸€èµ° Stage-1: GRASP â†’ LS â†’ LNSï¼‰
    # build_and_save_stage1_plans(
    #     save_path="plans.json",
    #     max_module_size=3,
    #     grasp_weights=weights,  # å¯ä¼  None ä½¿ç”¨é»˜è®¤
    #     params=params,  # å¯ä¼  None ä½¿ç”¨é»˜è®¤
    #     seed=42
    # )

    # 2) è®­ç»ƒï¼ˆå¸¦çº¦æŸçš„ç¦»æ•£ SACï¼‰
    print("--- Training TriPart (Constrained Discrete SAC) ---")
    algo = train_tripart_csac(
        total_steps=200_000,
        seed=42,
        K_s_max=3,
        K_a_max=3,
        precomputed_plans_path="plans.json"
    )

    # 3) è¯„ä¼°ï¼ˆæ²¿ç”¨ä½ åŸæœ‰ evaluate_tripart å³å¯ï¼Œä¼ å…¥ä¸€ä¸ªâ€œå¸¦ act çš„ä»£ç†â€ï¼‰
    print("--- Evaluating ---")


    # ç®€å•é€‚é…ï¼šç”¨ç®—æ³•çš„ policy.act æ¥â€œé¢„æµ‹â€åŠ¨ä½œ
    class _ActorWrap:
        def __init__(self, algo): self.algo = algo

        def predict(self, obs, deterministic=True):
            a, _ = algo.policy.act(_to_torch_obs(obs, algo.device), deterministic=deterministic)
            return a[0], None


    print("--- Evaluating (cSAC) ---")
    eval_result = evaluate_tripart_csac(algo, episodes=10, seed=999, deterministic=True)
    print("--- Done ---")
